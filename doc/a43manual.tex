\documentclass[oribibl]{llncs}

\usepackage{units}
\usepackage{psfrag} %% psfrac does not work with pdflatex
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{microtype}
\usepackage{subfigure}
\usepackage{todonotes} %% add [disable] to disable
\usepackage{transparent}
\usepackage{pgfplots}

\usepackage{acronym} %% for abbreviations
\acrodef{dft}[DFT]{density functional theory}
\acrodef{xc}[XC]{exchange-correlation}
\acrodef{sho}[SHO]{spherical harmonic oscillator}
\acrodef{dos}[DoS]{density of states}
\acrodef{ho}[HO]{harmonic oscillator}
\acrodef{pw}[PW]{plane wave}
\acrodef{gp}[GP]{grid point}
\acrodef{ae}[AE]{all-electron}
\acrodef{paw}[PAW]{Projector Augmented Wave}

\acrodef{cpu}[CPU]{central processing unit}
\acrodef{gpu}[GPU]{graphical processing unit}
\acrodef{hpc}[HPC]{high performance computing}
\acrodef{omp}[OpenMP]{OpenMP}
\acrodef{mpi}[MPI]{message passing interface}


\setlength{\tabcolsep}{6pt}

\newcommand{\um}[1]{_{\mathrm{#1}}}
\newcommand{\ttt}[1]{\texttt{#1}}
\newcommand{\lmax}{\ell_{\mathrm{max}}}
\newcommand{\ellm}{L}
\newcommand{\nrn}{n_{\mathrm{r}}}
\newcommand{\ket}[1]{\left| #1 \right\rangle}
\newcommand{\bra}[1]{\left\langle #1 \right|}
\newcommand{\braket}[2]{\left\langle \left. #1 \right| #2 \right\rangle}
\newcommand{\braketop}[3]{\left\langle \left. #1 \right| #2 \left| #3 \right. \right\rangle}
\newcommand{\codename}{A4cube}

\begin{document}
\pagestyle{plain}

\title       {\codename{} - User Manual}
\titlerunning{\codename{}}

\author{%
  Paul F.~Baumeister\inst{1} % \and %
}

\institute{%
  J\"{u}lich Supercomputing Centre, Forschungszentrum J\"{u}lich, 52425 J\"{u}lich, Germany
%   \and Institute for Advanced Simulation, Forschungszentrum J\"{u}lich, 52425 J\"{u}lich, Germany
}

\maketitle

\begin{figure*}
	\centering
	\includegraphics[width=3cm]{fig/a43_logo_bold_no_helper_lines} %%
\end{figure*}

% ==============================================================================
\begin{abstract}
This is a user manual for everyone who is interested in using
this software.
As far as possible, all aspects of programming are omitted here.
However, some aspects related to the algorithms that the applications 
makes use of will need be covered in order to explain the handling.
\end{abstract}
% ==============================================================================

\section*{How to read this document?}
\todo[inline]{Write}

\newpage
% ==============================================================================
\section{Introduction} \label{sec:intro}
% ==============================================================================
%
\subsection{Density Functional Theory}
\codename{} is an implementation for performing calculations in the framework of \ac{dft}.
A fair number of books and a vast number of articles in the scientific 
literature is on \ac{dft}, therefore, we will only give a brief recap 
of the very basics needed to understand what kind of physics can be
simulated with \codename{} and also, where the limitations of predictive power
are.

\ac{dft} is a ground state method, this means that in principle we have to
assume zero Kelvin. However, you will see later that for special situations 
finite temperatures are applied to smear out the Fermi-Dirac distribution 
for electronic occupation numbers in order to improve convergence.
In principle, all results should be extrapolated to \unit[0]{K}.


The underlying Hohenberg-Kohn theorem tells us, that we can derive some 
ground state properties of the system once we have found the correct density.
In order to find the density, Kohn and Sham introduced single-particle wave functions $\Psi_i$, which are eigenstates of an effective single-particle Hamiltonian $\hat H$.
With a little simplification, we can write the total electron density
\begin{equation}
	n(\vec r) = \sum_i^{\mathrm{occ}} \left| \Psi_i(\vec r) \right|^2
	\label{eqn:simplified_density_generation}
\end{equation} 
As a function or functional of the density $n(\vec r)$ we can construct
a local effective potential entering the Hamiltonian
\begin{equation}
	\hat H\um{Kohn-Sham} = \frac{\left( \imath \hbar \vec \nabla \right)^2}{2 m_e} + V\um{eff}(\vec r)
	\label{eqn:Kohn-Sham_Hamiltonian_no_spin}
\end{equation} 
where $V\um{eff}(\vec r)$ includes
\begin{itemize}
  \item the attractive Coulomb potential of the atomic nuclei,
  \item a repulsive Hartree potential from electrostatic 
  		interaction of an electron with the density,
  \item a contribution accounting for exchange and electronic correlation
  \item and potential external fields.
\end{itemize}

\subsection{The Exchange-Correlation Functional}
The true many-body wave function for a system with electrons (as being Fermions)
is anti-symmetric under exchange of two particles. 
This implies that e.g.~a two electrons wave function $\Psi(\vec r_1,\vec r_2)$ must be zero whenever $\vec r_1 \rightarrow \vec r_2$ in order to obey
the anti-symmetry constraint.
This lowers the repulsion energy of a real two-electrons system compared to a
system of independent charged particles.
In \ac{dft} the construction of independent single-particle states is an approximation that requires to model the exchange interaction.

Furthermore, there are correlation effects of true many-body electron systems
which also cannot be easily captured in standard \ac{dft}.
Both together are modelled in the contribution $V\um{xc}(\vec r)$ 
to the total effective potential and a corresponding energy density $\epsilon\um{xc}$ for the evaluation of a total energy.

Different parametrizations of the \ac{xc} functional are available.
\codename{} focusses onto the three classes of local (non-orbital dependent) functionals: 
\begin{itemize}
	\item Local (Spin) Density Approximations, LDA/LSDA, 
	\item Generalized Gradient Approximations, GGA
	\item Meta-GGAs
\end{itemize}
LDAs generate $V(\vec r)$ only from the value of $n(\vec r)$, 
hence the name \emph{local}. 
GGAs include some gradients of the density, $|\vec \nabla n(\vec r)|$.
Still, the spatial argument $\vec r$ is the same but thinking for example
in terms of finite-difference derivatives on a grid, 
a little non-local character of GGAs becomes visible.
Finally, meta-GGAs incorporate information about the kinetic energy density.
In analogy to eq.~(\ref{eqn:simplified_density_generation}), the kinetic energy density $\tau$ can be found by
\begin{equation}
	\tau(\vec r) = \frac{\hbar^2}{2m_e} \sum_i^{\mathrm{occ}} \braketop{ \Psi_i } {\vec \nabla^2 } { \Psi_i } 
	\label{eqn:simplified_kinetic_energy_density_generation}
\end{equation}
where we introduced Dirac's \emph{bra-ket} notation.
Currently, only the LSDA Perdew-Zunger'81 \ttt{PZ81} is implemented 
but it is planned to interface \ttt{libxc} with access to most existing functional.
\todo[inline]{Implement LIBXC, reference for LIBXC}



\section{How to get started}

\subsection{Getting the Code}
\codename{} will be public domain software under the MIT license
and will be available to clone or download at \ttt{github.com}. 
\todo[inline]{get GitHub account}
\todo[inline]{Add MIT license headers}

\subsection{Building the Application} \label{sec:compiling}
A \ttt{Makefile} is contained in the program package that works with current GNU compilers, e.g.~\ttt{g++ 7.4.0}.
%% and \ttt{nvcc from CUDA 10}

The application, while being written in C++, relies strongly onto plane-old-data types,
i.e.~classes without constructors or destructors as known from C-structs.
Furthermore, it makes use of generic programming in the form of templates
mainly used to maintain a single functions supporting different precision (\ttt{float} or \ttt{double}), 
difference vector lengths and in some situations different physics. 
This helps to keep the code base small and, hence, maintainable.

\section{Basic Handling}
\codename{} comes as a single executable named \ttt{a43} which
offers many functionalities accessible by options. Type \ttt{./a43 -h}
to get a first help function:
\begin{verbatim}
Usage ./a43 [OPTION]
   -h, -H       This help message
   -t <module>  Test module
   +<var>=<val> Modify variable environment
\end{verbatim}

An important functionality after building the application (see section \ref{sec:compiling}) 
is to run a self test of the available modules.
In order to get a rough list of potential modules, 
use \ttt{ls *.hxx} in the \ttt{src/}-directory.
Pass the name of the module to run a self test like this
\begin{verbatim}
./a43 -t geometry_analysis.
\end{verbatim}
Mind that we need to skip the file suffix \ttt{hxx} or \ttt{cxx} but not the dot.
We can also run all module tests, however, for this we might want to reduce
the amount of output to \ttt{stdout}. 
Simply, we use the variable environment which couples to the command line interface:
\begin{verbatim}
./a43 +verbosity=1 -t
\end{verbatim}
The default \ttt{verbosity}-level is $3$ and levels are adjusted frequently.
However, the ground rule says that higher \ttt{verbosity} means more output
and \ttt{verbosity=0} suppresses all output except for fatal errors.

\subsection{Atomic Units, Input and Output}
Internally the code makes use of atomic Hartree units:
\begin{equation}
	\hbar = m_e = e = 1
\end{equation}
as this reduces the number of non-trivial factors in many equations.
This means that the internal unit of length is Bohr = \unit[0.529177]{\AA{}}
and the internal unit of energy is Hartree = \unit[27.2114]{$e$V}.
However, we can change the length and energy units used for output like this:
\begin{verbatim}
./a43 +output.energy.unit=eV +output.length.unit=Ang ...
\end{verbatim}
Available output units are \ttt{eV}, \ttt{Ry} or \ttt{Ha} (default in the development branch) for energies 
and \ttt{nm}, \ttt{Ang} (=\AA) and \ttt{Bohr} (default) for lengths.
Input length units are \AA{} in the geometry file as this is most convenient for molecular structure viewers
(\ttt{VESTA}, \ttt{jmol}, etc.). Other input quantities may have flexible input units, for example
\begin{verbatim}
./a43 +logder.unit=Ry +logder.step=1e-3
\end{verbatim}
which means that the energy spacing for checking of the logarithmic derivatives is milliRydberg.
% The same input unit is assumed for \ttt{+logder.start} and \ttt{+logder.stop}.


Experimental parts of the code may not support all the unit conversion
factors for output. Then you should be able to find at least \ttt{Ha}, \ttt{Bohr} or simply \ttt{a.u.} in the log files.
Most standard functionality, however, supports unit conversion so that log files
show \ttt{eV} or \ttt{Ry} and \ttt{Ang}$ = $\AA{} or \ttt{nm}, depending on the users choice.
Some quantities are displayed in characteristic units, e.g., plane wave cutoffs typically in Rydberg.


\subsection{Try a first structure}
Make sure there is structure file \ttt{atoms.xyz} file and run
\begin{verbatim}
./a43 -t geometry_analysis.
\end{verbatim}
in order to check if your geometry looks ok.
Search the log file for warnings using \ttt{grep}.
There will also be a summary of all warnings launched during the execution at the end of the log file.
Once free of warnings, continue with the next step:
Let's say we want Aluminum in our system, then run:
\begin{verbatim}
./a43 -t single_atom. +single_atom.test.Z=13
\end{verbatim}


\codename{} will the try to access a database of initial atomic potentials
(full spherically, spin-degenerate) which are stored in \ttt{pot/Zeff.}$Z$
where $Z$ is a 3-digit integer atomic number.
\todo[inline]{make the path to pot/ configurable}
You can even add \ttt{+single\_atom.init.scf.maxit=33} to let the atomic density relax if e.g.~the \ac{xc} functional differs from the one that was used to generate the \ttt{Zeff.}-file.
If the loading fails because of a missing file, you can bootstrap it:
\begin{verbatim}
./a43 -t atom_core. +atom_core.test.Z=13
\end{verbatim}
or if the entire database was lost,
\begin{verbatim}
./a43 -t atom_core. \
        +atom_core.test.Z=1 +atom_core.test.Z.end=99
\end{verbatim}

Now, run the \ttt{single\_atom.} test for each of the elements in the system to see if there are warnings before you continue like this
\begin{verbatim}
./a43 -t potential_generator. \
        +geometry.file=molecule.xyz +verbosity=3
\end{verbatim}
\todo[inline]{we have not yet defined a functionality of main! only tests so far}

For the advanced user, we recommend to inspect the logarithmic derivatives by
\begin{verbatim}
./a43 -t single_atom. +single_atom.test.Z=13 \
        +logder.start=-4 +logder.step=1e-4 +logder.stop=1.0
\end{verbatim}
The output can be visualized by \ttt{gnuplot} or \ttt{xmgrace -nxy}.
For the ease of use, we may add \ttt{+logder.unit=eV} and then specify
start, stop and step in units of $e$Volt.

\subsection{Parallel Computing}
Currently, some parts of \codename{} support shared memory parallelism 
via \ttt{omp} threads on the \ac{cpu}.
In order to target current \ac{hpc} systems 
the goal is to incorporate the \ac{mpi}
for inter-node communication
and the \ttt{CUDA} programming model for acceleration by a \ac{gpu}.
\todo[inline]{MPI parallelize}
\todo[inline]{Import CUDA finite-difference from ReSpawN}
\todo[inline]{Import CUDA sho-transform from ReSpawN}
\todo[inline]{Import CUDA tfqmr from tfQMRgpu}

Please consult with your \ac{hpc} system administrator for support
about how to control the different levels of parallelism.

\section{Representation of Wave Functions}

Kohn-Sham eigenstates have very different character depending on their energy level: core states, valence states and depending on the species also semicore states.
\subsubsection{Treatment of Core States}
Core states are very low in energy and strongly bound 
to the atomic core.
Their spatial extent is so strongly localized 
in the vicinity of the atomic nucleus 
that they feel almost exclusively the strong attractive 
(effective because screened) Coulomb potential of the core. 
This can be approximated fairly well as a spherically symmetric potential.
with a singularity at its origin.
The eigenstates show a clear $\ell$-character, 
i.e.~$s$, $p$, $d$ or even $f$ states can be found.
Technically, the solutions are found on a 1D radial grid,
where also relativistic effects can be treated properly.
The energy is well defined and degenerate with respect to
the magnetic quantum number $m$.

\subsubsection{Treatment of Semicore States}
Semicore states are high-lying core states
but energy-wise below the valence band.
Their wave function tail can extend beyond half a nearest neighbor atom distance.
In a tight-binding picture, the hoppings to the neighboring atom are still small
but the non-sphericality of the potential becomes important.
The $m$-degeneracy of the energy (found for core states) breaks 
and crystal field splittings or even bands with small dispersion can be observed.
\todo[inline]{Implement semicores}
It is planned to implement semicore states with a separate energy window
and either tight-binding like derived from atomic orbitals 
(eigenfunctions of the spherically averaged potential) 
or with a full \ac{paw} treatment as follows for the valence states.

\subsubsection{Treatment of Valence States}
Valence states are high in energy, by definition up to the Fermi
energy, are delocalized over several atoms and form bands and bonds.
They are particularly difficult to describe because of the 
inhomgeneiety of features:
Valence states exhibit relatively slow oscillations 
in the space between atoms (interstitial space) but close to the atomic nuclei,
their structure resembles that of high-lying core states.
In particular projected radial coordinates, we can find up to $6$ nodes
(7$s$-bands) with the distance between the nodes becoming smaller
the closer we move towards the core.
These rapid oscillations are difficult to represent
on the same footing that gets the behaviour in the interstitial regions correct. 
We will review some of the most common approaches:

Local orbital methods use radial eigenfunctions 
of the spherically averaged atomic potential as atom-centered basis functions.
This captures the behaviour in the core region well
but shows a slow and not systematic convergence behaviour in the interstitial region. 
An advantage is that atomic orbital basis sets can be rather compact
and localized which casts the Hamiltonian into a block-sparse matrix operator with small block dimensions ($\approx 30$).
The drawback is that the description in the interstitial region determines the
quality of description for bandstructures, bonds and forces.

LAPW (Linearized Augmented Plane Wave) methods take the best of two worlds:
In order to construct efficient basis functions, 
they assume a spherical potential inside an atomic sphere (solutions are radial)
and a constant potential inside the interstitial region (solutions are plane waves). 
On the boundary spheres between the two regions, the basis function components need to be matched.
Due to the \ac{pw}-character, the basis functions are fully delocalized and 
the Hamiltonian becomes dense.

Using \ac{pw}s as a basis for the entire space shifts the problem to the representation of the valence wave function in the core region.
The \ac{paw} method is a successful generalization of the family of pseudopotential methods with allows a full-potential access.
A pseudopotential replaces the true deep full potential in the core region
by some potential which can be represented with a finite number of \ac{pw}s
and approximates the scattering properties (phase shifts) in the typical energy
range of valence states.
In most cases the construction of such a potential only succeeds in the form of
a non-local potential.

Real-space grid based methods for \ac{dft}
feature an improved scalablity on massively parallel \ac{hpc} systems at the same level of accuracy as \ac{pw} basis sets. 
The \ac{paw} method can be utilized and comes at the advantage that the projector functions are localized around the atoms, 
hence, the Hamiltonian becomes an implicit low-rank operator with sparsity which does not involve Fourier transforms when applied to a wave function.


\codename{} implements Cartesian real-space grids 
in combination with a revision of the \ac{paw} method (revPAW) suitable for
a reduced memory capacity consumption and lower memory bandwidth requirements.
%% ToDo: cite Baumeister, Tsukamoto, PASC19


% ==============================================================================
\bibliographystyle{splncs03} \bibliography{literature}
% ==============================================================================

\end{document}
