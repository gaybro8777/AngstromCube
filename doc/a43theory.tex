\documentclass[oribibl]{llncs}

\usepackage{units}
\usepackage{psfrag} %% psfrac does not work with pdflatex
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{microtype}
\usepackage{subfigure}
\usepackage{todonotes} %% add [disable] to disable
\usepackage{transparent}
\usepackage{pgfplots}

\usepackage{acronym} %% for abbreviations
\acrodef{dft}[DFT]{density functional theory}
\acrodef{sho}[SHO]{spherical harmonic oscillator}
\acrodef{dos}[DoS]{density of states}
\acrodef{ho}[HO]{harmonic oscillator}
\acrodef{planewave}[PW]{plane wave}
\acrodef{gridpoint}[GP]{grid point}
\acrodef{paw}[PAW]{Projector Augmented Wave}
\acrodef{xc}[XC]{exchange-correlation}


\setlength{\tabcolsep}{6pt}

\newcommand{\m}[1]{{\mathrm{#1}}}
\newcommand{\um}[1]{_{\mathrm{#1}}}
\newcommand{\ttt}[1]{\texttt{#1}}
\newcommand{\lmax}{\ell_{\mathrm{max}}}
\newcommand{\ellm}{L}
\newcommand{\nrn}{n_{\mathrm{r}}}
\newcommand{\ket}[1]{\left| #1 \right\rangle}
\newcommand{\bra}[1]{\left\langle #1 \right|}
\newcommand{\braket}[2]{\left\langle \left. #1 \right| #2 \right\rangle}
\newcommand{\braketop}[3]{\left\langle \left. #1 \right| #2 \left| #3 \right. \right\rangle}
\newcommand{\numax}{\nu\um{max}}

\begin{document}
\pagestyle{plain}

\title       {Spherical Harmonic Oscillator Basis}
\titlerunning{Spherical Harmonic Oscillator Basis}

\author{%
  Paul F.~Baumeister\inst{1} % \and %
}

\institute{%
  J\"{u}lich Supercomputing Centre, Forschungszentrum J\"{u}lich, 52425 J\"{u}lich, Germany
%   \and Institute for Advanced Simulation, Forschungszentrum J\"{u}lich, 52425 J\"{u}lich, Germany
}

\maketitle

\begin{figure*}
	\centering
	\includegraphics[width=3cm]{fig/aa3_logo_bold_no_helper_lines} %%
\end{figure*}

% ==============================================================================
\begin{abstract}
\todo[inline]{write abstract}
\end{abstract}
% ==============================================================================


\newpage
% ==============================================================================
\section{Introduction} \label{sec:intro}
% ==============================================================================
%
Real-space grid based methods for \ac{dft}
have proven to yield good parallelizability and the same level of
accuracy as \ac{planewave} basis sets.
The latter aspect is in particular true for results converged
in terms of the number of \acp{planewave} compared to those converged
w.r.t.~the grid spacing.
However, real-space grid methods cannot be operated at very coarse
grid spacings due to unphysical interferences between the position
of atoms relative to the position of grid points.
This leads to relatively high cost prefactors (for time and space)
of the real-space methods compared to \ac{planewave} basis sets
when we want to do a fast but less accurate calcuation.
Furthermore, the iterative solver schemes applied in real-space
grid formalism often deteriorate in terms of their convergence
velocity when the number of grid points increases.
This is due to the limited width of the stencil compared to the 
global scale of the non-local solutions.
Therefore, convergence acceleration is crutial here.
In many situations, switching to a \ac{planewave} representation
is a viable option for an efficient preconditioner as
\acp{planewave} contain the full non-locality.
Then again, \acp{planewave} destroy the parallelizability
to some extend.
The approach investigated in this project is a small basis of atom-centered
localized orbitals.
This basis is not meant to produce as accurate results as \acp{gridpoint} or \acp{planewave}
or to feature a advantageous convergence w.r.t.~costs
but to be simple and cheap in its construction (low number of control parameters)
and to produce approximately right physics already at small basis sets.
If in addition we can define an efficient transformation between
representations in
the small localized basis set and grid-based representations
this basis can be used to accelerate
the congerence of a real-space grid-based method.

% ==============================================================================
\section{Spherical Harmonic Oscillator} \label{sec:sho}
% ==============================================================================
%
The quantum-mechanical \ac{ho} has the Hamiltonian
\begin{equation}
  \hat H^{[1D]}_{\sigma} = -\frac{\partial_x^2}{2} + \frac{x^2}{2 \sigma^4} \text{.}
  \label{eqn:HO-Hamiltonian}
\end{equation}
Hartree atomic units are used throughout this document.
Here, $\sigma$ is a lengthscale parameter that also fixes the scale of the eigenenergies
\begin{equation}
  E^{[1D]}_{n}(\sigma) = \sigma^{-2} \left( n + \frac 12 \right) \text{.}
  \label{eqn:HO-eigenenergy}
\end{equation}
The \ac{ho} eigenfunctions are
\begin{equation}
  \psi^{[1D]}_{n}(x) = H_n(x/\sigma) \cdot \exp\left( -\frac{x^2}{2 \sigma^2} \right) 
  \label{eqn:HO-eigenfunction}
\end{equation}
with the Hermite polynomials $H_n$.
\todo[inline]{add normalization constants}

The eigenfunctions of the quantum-mechanical 
three-dimensional isotropic harmonic oscillator 
- in the following we will refer to it as \ac{sho} -
can be written as Cartesian product of three
\ac{ho} eigenfunctions
\begin{equation}
  \hat H^{[3D]}_{\sigma} = -\frac{\vec \nabla^2}{2} + \frac{\vec r^2}{2 \sigma^{4}} 
  \label{eqn:SHO-Hamiltonian}
\end{equation}
has the solutions
\begin{equation}
  \psi^{[3D]}_{n_x n_y n_z}(x,y,z) = \psi^{[1D]}_{n_x}(x/\sigma) 
                               \cdot \psi^{[1D]}_{n_y}(y/\sigma) 
                               \cdot \psi^{[1D]}_{n_z}(z/\sigma) 
  \label{eqn:SHO-eigenfunction}
\end{equation}
and the eigenenergies
\begin{equation}
  E^{[3D]}_{n_x n_y n_z}(\sigma) = \sigma^{-2} \left( n_x + n_y + n_z + \frac 32 \right) 
  \label{eqn:SHO-eigenenergy}
\end{equation}

Furthermore, the \ac{sho} can be solved in spherical coordinates 
exploiting its spherical symmetry.
This leads to the quantum numbers $\nrn, \ell$ and $m$
and the eigenstates
\begin{equation}
  \psi_{\nrn \ell m}(r,\vartheta,\varphi) = R_{\nrn \ell}(r/\sigma) 
                               \cdot Y_{\ell m}(\vartheta,\varphi)
  \label{eqn:SHO-eigenfunction-radial}
\end{equation}
with the radial function
\begin{equation}
  R_{\nrn \ell}(r) = r^\ell \cdot L^{(\ell + \frac 12)}_{\nrn}(r^2) \cdot \exp(-\frac{r^2}2)
  \label{eqn:SHO-radial-eigenfunction}
\end{equation}
where $L_n^{(\alpha)}$ stands for the associated Laguerre polynomials.
\todo[inline]{add normalization constants}

In the code, spherical harmonics $Y_{\ell m}$ usually appear in their representation
$X_{\ell \mu}$ where each $\mu$ stands for a real-valued linear combination of $m$ and -$m$.
\todo[inline]{cite Homeier}

\begin{figure}
	%%% how to generate this plot: 
	%%% ./aa3 -t hermite_polynomial. +verbosity=10
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/hermite_gauss_functions} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:hermite_gauss_function}
  \caption{
  Hermite-Gauss functions up to $n\um{max} = 5$.
  }
\end{figure}


\subsection{SHO as a basis}
An infinite set of all \ac{sho} eigenfunctions forms a basis of the function space over $\mathbb R^3$.
Limiting the set by cut-off energy $E\um{cut} = \sigma^{-2} (\nu\um{max} + \frac 32)$
creates a finite basis.
If we create a union of finite bases centered at each atom $a$ in a \ac{dft} calculation 
we only need to choose a $\sigma$ and $\nu\um{max}$ for each atomic species.
\begin{equation}
  \chi_{a n_x n_y n_z}(x,y,z) = \psi^{[1D]}_{n_x}((x - x_a)/\sigma_a) 
                          \cdot \psi^{[1D]}_{n_y}((y - y_a)/\sigma_a) 
                          \cdot \psi^{[1D]}_{n_z}((z - z_a)/\sigma_a)
  \label{eqn:localized-basis}
\end{equation}
See fig.~\ref{fig:HO-basis-on-2-atoms}.
This union is, understandably non-orthogonal, in particular when the orbital centers
are close enough so that the basis functions from neighboring centers gain an overlap.
%
\begin{figure}
  \begin{minipage}[c]{.58\textwidth}
	\includegraphics[width=\textwidth]{fig/HO-basis-on-2-atoms} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.41\textwidth}
  
%%%% generated by fig/HO-basis-on-2-atoms.F90
%    0.082  -0.183   0.290   1.000  -0.000  -0.000
%   -0.183   0.328  -0.389  -0.000   1.000   0.000
%    0.290  -0.389   0.288  -0.000   0.000   1.000

		\begin{tabular}{r rrr}
		\toprule
				    & $\ket{s_0}$ & $\ket{p_0}$ & $\ket{d_0}$ \\
% 		\midrule
				$\bra{s_1}$  &      0.082 &  -0.183 &  0.290  \\
				$\bra{p_1}$  &     -0.183 &   0.328 & -0.389  \\
				$\bra{d_1}$  &      0.290 &  -0.389 &  0.288  \\
		\bottomrule
		\end{tabular}

  \end{minipage}
  \label{fig:HO-basis-on-2-atoms}
  \caption{
Schematic picture to illuminate the non-orthogonal localized basis in 1D.
On each atomic position \ac{ho} basis functions are centered.
Here, $\sigma$ has been chosen such that $d$-orbitals can form bonds (green lines).
The non-trivial part of the overlap matrix is shown on the right.
  }
\end{figure}
%
%

Then the evaluation of matrix elements works as follows:

\subsubsection{Overlap matrix elements}
Basis functions $\chi$ centered at the same atom $a$ are orthogonal by construction
so we at most need to take care of their normalization.
We assume that an atom is positioned at $\vec R_a = \{ X_a, Y_a, Z_a \}$ or $\{ X_{1a}, X_{2a}, X_{3a} \}$.
For any pair of atoms $(a,a')$, we can compute the overlap element
\begin{equation}
  \braket{ \chi_{a n_x n_y n_z} }{ \chi_{a' n'_x n'_y n'_z} } = \prod_{i=1}^D
  \int\mathrm d x_i \  \psi^{[1D]}_{n_{x_i}}((x_i - X_{ia})/\sigma_a)
                    \  \psi^{[1D]}_{n'_{x_i}}((x_i - X_{ia'})/\sigma_{a'})
  \label{eqn:overlap-factorized}
\end{equation}
In each of the integrals we can exploit that the product 
of two Gaussians with spread $\sigma_a$ and $\sigma_{a'}$ 
centered at $x_a$ and $x_{a'}$, respectively, 
is again a Gaussian $\exp(-\vec r^2 \sigma_p^{-2})$ with spread $\sigma_p = \left(\sigma_a^{-2} + \sigma_{a'}^{-2}\right)^{-\frac12}$
centered at $\sigma_p^2 \left( \sigma_a^{-2} \vec R_a + \sigma_{a'}^{-2} \vec R_{a'} \right)$.
The polynomial expressions can be shifted to the new center and multiplied there.
See fig.~\ref{fig:overlap_1D} for an impression of the 1D overlap values 
as a function of distance the centers.
Finally, the integration reduces the the evaluation of the kernel
\begin{equation}
  I_k = \int\limits_{-\infty}^{\infty} \mathrm d x \  \exp(-x^2) \  x^{2k}
  \label{eqn:gauss-integral-kernel}
\end{equation}
which can be evaluated recursively by $I_{k+1} = (k + \frac12)\,I_k$ starting at $I_0 = \sqrt{\pi}$.
Mind that no approximations are required here.
%
\begin{figure}
	%%% how to generate this plot:
	%%% make -j && ./aa3 -t sho_overlap. +verbosity=9 | grep 'test_Hermite_Gauss_overlap' | sed -e 's/# test_Hermite_Gauss_overlap  distance=//g'
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/overlap_1D} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:overlap_1D}
  \caption{
	The overlap integral values of two 1D \ac{ho} eigenfunctions (both with spread $\sigma$)
	as a function of distance between their centers.
	Only an upper triangle of combinations $(n,n')$ up to $n\um{max} = 3$ is shown.
  }
\end{figure}
%
%


\subsubsection{Hamiltonian matrix elements}
The \ac{dft} Hamiltonian consists of a kinetic energy operator,
a local effective potential 
and, if the basis is incapable of
capturing the rapid oscillations close to the nuclei,
a non-local contribution according to the \ac{paw} method.
A similar \ac{paw} contribution would then also appear in the overlap operator.
The kinetic energy consists of a Laplacian so we can boil it down to the evaluation
of $\braketop{ \psi^{[1D]}_{an} }{ \partial^2_x }{ \psi^{[1D]}_{a'n'} }$.
This works just as outlined for the overlap elements
except for the derivative operator modifying the polynomials before contraction with the integration kernel $I_k$.
Mind that in order to produce symmetric matrix elements,
a first derivative should be applied to the left and a first derivative to the right.
It is easy to show that applying the second derivative to the left in general differs from
the matrix element that we obtain if we apply the second derivative to the right.

The non-linearity of the exchange-correlation potential in \ac{dft} usually
leads to a representation of the local potential $V(x,y,z)$ on a real-space grid.
We will assume a Cartesian uniform grid here.
Then, viable options to evaluate the potential matrix elements would be
\begin{itemize}
%
\item to evaluate $\braketop{ \chi }{ \hat V }{ \chi' }$ numerically. 
This may lead to a large cost prefactor but scales linearly with the number of atoms due to the localization of $\chi$s.
This method has been used to find reference values during development. This is referenced as \ttt{Method1}.
%
\item for each pair $(a,a')$ which is not too distant
compute an expansion of $V(\vec r)$ into a \ac{sho} basis with spread $\sigma_p$
at the common center and perform the product and integral there. This is referenced as \ttt{Method2}.
%
\item for each atom $a$ expand $V(\vec r)$ into a suitable \ac{sho} basis. 
Then, we can insert a completeness relation: %%  (truncation of unity?)
\begin{equation}
 \braketop{ \chi_{a\vec n} }{ \hat V }{ \chi_{a'\vec n'} } = \sum_{\vec n''}
 \braketop{ \chi_{a\vec n} }{ \hat V }{ \chi_{a\vec n''} } \braket{ \chi_{a\vec n''} }{ \chi_{a'\vec n'} }
\end{equation}
such that all Gaussian are centered at the position of atom $a$ for the expectation value
and the second integral is the same as for the overlap operator.
Mind that we inserted a complete basis $\chi_{a\vec n''}$. 
This means that the convergence w.r.t.~the cut-off for $\vec n''$ needs to be checked carefully.
Due to different convergence rates, the potential matrix $\hat V$ might not be symmetric
requiring symmetrization according to $\hat V\um{sym} = \frac 12 \left( \hat V + \hat V^\dagger \right)$. This is referenced as \ttt{Method4}.
%
\end{itemize}
In the following, we will discuss \ttt{Method2} and \ttt{Method4}.

\subsubsection{Potential matrix elements by Method2}
For each pair of atoms 
(or, more precise for the periodic case, atomic image positions)
$(a,a')$ compute an expansion of $V(\vec r)$ into a \ac{sho} basis with spread $\sigma_p$
at the common center and perform the product and integral there.
The basis functions have polynomial degree up to $\numax_a$.
When the expansion of the polynomials is shifted to the common center
the polynomial coefficients change, however, the maximum degree stays unaffected.


\subsubsection{Potential matrix elements by Method4}


Finally, non-local potentials are usually expressed as dyadic operators
$\ket{\tilde p^a_i} D^a_{ij} \bra{\tilde p_j}$ with localized projector functions $\tilde p_i(\vec r)$
centered at the atomic positions.
% We can expand the projectors in a suitable \ac{sho} basis and use the same method
% as for overlap elements~\cite{BaumeisterTsukamotoPASC19}.
We can expand the projectors in a suitable \ac{sho} basis and use the same method
as for matrix elements of the local potential.~\cite{BaumeisterTsukamotoPASC19}.

%
\begin{figure}
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/GaussianProductRule} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:GaussianProductRule}
  \caption{
Schematic picture to illuminate the Gaussian product rule. Blue is the product of red and green.
Due to the larger spread of the red Gaussian, the origin of the product (center of mass) is much closer to
the origin of the green Gaussian.
  }
\end{figure}
%
%


\subsubsection{Expansion of the Density}
If the local \ac{sho} basis with $\sigma$ and $\nu\um{max}$
is suitable to describe wave functions, 
a suitable \ac{sho} basis for the expansion of the density $\varrho(\vec r)$ has
spread $\sigma_a/\sqrt{2}$ and $2\nu\um{max}$.
This is due to the representation of densities
arising from basis functions local to an atom, c.f.~fig.~\ref{fig:plot_parabolas}.
%
\begin{figure}
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/plot_parabolas} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:plot_parabolas}
  \caption{
Schematic picture to illuminate the relation between the SHO basis configuration 
used to describe densities
compared to the SHO basis for wave functions:
If wave functions are expanded into a Hermite-Gauss basis with spread $\sigma$
up to $n\um{max}$ (here, the $n = 5$ function is shown in blue)
the square of such a wave function leads to the function shown in purple:
A Gaussian with spread $\sigma^{[\varrho]}$ times a polynomial with max.~degree $n\um{max}^{[\varrho]}$.
This function can be exactly expanded by a Hermite-Gauss basis if
$\sqrt{2}\,\sigma^{[\varrho]} = \sigma$
and
$n\um{max}^{[\varrho]} = 2n\um{max}$.
The highest Hermite-Gauss function for $n\um{max}^{[\varrho]} = 10$ is shown in red.
The associated parabolas are shown in bold black and bold green.
In the limit of large $n\um{max}$, the classical return radius $R\um{ret}$
of both SHO bases coincides (grey dashed vertical lines).
The associated cut-off energy is $4$ times higher for the density basis.
  }
\end{figure}
%
%

So for the evaluation of the density,
we have to prepare this tensor of coefficients:
\begin{equation}
	P_{nn'n''} = \int \mathrm d x \ H_{n}(x) \exp(-x^2/2) \cdot H_{n''}(x\sqrt{2}) \exp(-x^2) \cdot H_{n'}(x) \exp(-x^2/2)
\end{equation}
where the indices $n$ and $n'$ are associated with the SHO basis for wavefunctions
and $n''$ runs up to $n\um{max}^{[\varrho]}$. 
Obviously, all $P_{nn'n''}$ are zero if $n + n' + n''$ is odd.

\subsubsection{Expansion of the Local Potential}
As described above, there are several ways to evaluate the matrix elements of the local effective potential $V(\vec r)$.
For this, we have to perform the integral
\begin{equation}
	\int \mathrm d^3 \vec r  \  \psi_{n_x}(x_a)\psi_{n_y}(y_a)\psi_{n_z}(z_a)  \  V(x,y,z) \ 
	                            \psi_{n'_x}(x_{a'})\psi_{n'_y}(y_{a'})\psi_{n'_z}(z_{a'})
	                            \label{eq:local_potential_matrix_element}
\end{equation}
where $x_{ia} = x_{i} - X_{ia}$, i.e.~atom centered coordinates.
Similar to the case of the density, the product of the two Gaussian envelop functions of the 
two \ac{sho} basis functions produces a Gaussian centered at the \emph{center of mass}, here labelled $c$, where
$2\sigma^2$ is defining the inverse of the \emph{mass}.
In order to evaluate eq.~(\ref{eq:local_potential_matrix_element}) we
expand $V(x,y,z)$ in 3D factorizable polynomials, i.e.
\begin{equation}
	V(x,y,z) = \sum_{m_x m_y m_z} V_{m_x m_y m_z} (x - X_c)^{m_x} (y - Y_c)^{m_y} (z - Z_c)^{m_z}
	                            \label{eq:local_potential_polynomial_expansion}
\end{equation}
The necessary expansion coefficients $V_{m_x m_y m_z}$ can be found by SHO-transform around the common center $c$:
\begin{equation}
	V_{n_x n_y n_z}(\sigma) = \int \mathrm d^3 \vec r  \   V(x,y,z) H_{n_x}(x - X_c) H_{n_y}(y - Y_c) H_{n_z}(z - Z_c) 
		\exp(-(\vec r - \vec R_c)^2/(2 \sigma^2))
	                            \label{eq:local_potential_projection}
\end{equation}
Here, the quantum numbers $\vec n$ are limited by $n_x + n_y + n_z \leq \numax$.
In order to find the coefficients $V_{m_x m_y m_z}$ we need to invert the kernel matrix connecting the two
representations. The kernel matrix can be constructed from 1D matrices:
%During the SHO tranform onto the local potential we need to take care of the normalizing prefactors:
%Typically, L2-normalizations are multiplied to the SHO projection coefficients 
%after the projection with unnormalized Hermite-Gauss functions.
%However, here, proper L1-normalization requires the matrix inverse of 
$$ f_{nm}(\sigma) = \sigma^m \int\limits_{-\infty}^{\infty} \mathrm dx \  H_{n}\left( \frac{x}{\sigma} \right) \  \exp\left( -\frac{x^2}{2\sigma^2} \right) \  \left(\frac{x}{\sigma}\right)^m $$
%%% sho_overlap::moment_normalization
%for $m \leq n$ which results in a triangular matrix that, in addition, 
These 1D matrices feature an even-odd parity, 
i.e.~matrix entries are only non-zero if both $m$ and $n$ are even or both are odd.
The kernel matrix has to be expanded in 3D before inversion due to the truncation
of indices. The set of linear equations to be solved reads:
$$ \sum_{m_x m_y m_z}^{m_x + m_y + m_z \leq \numax} f_{n_x m_x} f_{n_y m_y} f_{n_z m_z} V_{m_x m_y m_z} = V_{n_x n_y n_z} $$

\noindent
Then the evaluation of potential matrix elements requires only the 1D tensors
\begin{equation}
	M_{pnn'}^{aa'[x]} = \int \mathrm d x  \  \psi_{n}(x - X_{a}) \  (x - X_{c})^{p} \  \psi_{n'}(x - X_{a'})
	\label{eq:local_moment_matrix_elements}
\end{equation}
which only need to be re-computed when atoms update their positions
and can be expressed as polynomials times Gaussians, i.e.~analytical functions of $\sigma_a, \sigma_{a'}$ and $X_a - X_{a'}$.
The final expression for potential matrix elements between SHO basis function $(\vec n_a,\sigma_a)$ and $(\vec n_{a'},\sigma_{a'})$ reads
\begin{equation}
	\sum_{p_x p_y p_z} V_{p_x p_y p_z} \  M_{p_x n_x n'_x}^{aa'[x]} \  M_{p_y n_y n'_y}^{aa'[y]} \  M_{p_z n_z n'_z}^{aa'[z]}
	\label{eq:local_moment_matrix_elements_from_tensors}
\end{equation}

\section{Benchmark: Free Electron Gas}
The dispersion relation of the free electron gas is know to be
\begin{equation}
	E(\vec k)= \frac {\vec k^2} 2
\end{equation}
a simple parabola with its curvature related to the mass of the electron.
In a perodic setup, we have to consider also the periodic image parabolas
\begin{equation}
	E_n(\vec k) = \frac {(\vec k - \vec G_n)^2} 2
\end{equation}
As a test of the quality of \ac{sho} functions as a basis
we diagonalize the Laplacian operator that represents the
Hamiltonian.
We analyzed the three highly symmetric, cubic lattice structures with a single basis atom,
SC, BCC and FCC, finding that the overlap matrix can become singular at certain points of
the reciprocal space, see fig.~\ref{fig:overlap_lowest_eig}.
%
\begin{figure}
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/20190529_fcc_overlap_lowest_eig} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:overlap_lowest_eig}
  \caption{
	Lowest eigenvalue of the overlap operator as a function of a given path in the Brioullin zone for FCC.
  }
\end{figure}
%
%
In order to stabilize the method, the used spread $\sigma$ depends on the nearest neighbor distance $d\um{NN}$
and the basis size.
\begin{equation}
	\sigma\um{stable} = \frac34 \frac{ d\um{NN} }{ \sqrt{2 \nu\um{max} + 3} }
\end{equation}
Remember that $\sigma \sqrt{2 \nu\um{max} + 3}$ is the classical return radius.
The factor $0.75$ is chosen manually and seems to produce stable results.
%
\begin{figure}
  %% how to generate this plot:
  %%  set DoS = false in overlap.cxx test_fcc
  %% 	run -t overlap. and set Ref = true   and nmax high for the analytical reference
  %% 	run -t overlap. and set Ref = false  and nmax = 8
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/20190710_overlap_fcc8} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:overlap_fcc8}
  \caption{
	Bandstructure of the free electron gas. The analytical solution is shown in red
	whereas the black lines show the \ac{sho} basis result for $\nu\um{max} = 8$ and $\sigma = 1.2$ Bohr 
	while the FCC lattice constant is $8$ Bohr.
  }
\end{figure}
%
%
Since we know that eigenstates of the free electron Hamiltonian are plane waves,
this gives an estimate of how good a \ac{sho} basis is capable of describing
smooth quantities in full space. 
In fig.~\ref{fig:overlap_fcc8} we can see that the black lines are on top of the 
analytical solutions for lower energies and above that in the upper half.
In order to study the deviations better,
we have a look at the integrated \ac{dos}.
For this we diagonalize the free electron Hamiltonian for each $\vec k$-point
in the irriducible wedge of the Brillouin zone
and compare again with the integrated \ac{dos} derived from the analytical solution $E_n(\vec k)$
with the same sampling.
Fig.~\ref{fig:overlap_DoS_free_electron_fcc} shows the result for $\nu\um{max} \in [0, 9]$,
each using its distinct $\sigma\um{stable}$.
The plot helps to quantify the deviations. For example with $\nu\um{max} = 9$, the \ac{sho}
basis describes the free electron gas well up to about $5$ Rydberg, 
but features solutions up to $20.8$ Rydberg where the highest analytical solution
within $220$ states is only $13.7$ Rydberg,
c.f.~the red and black dot in fig.~\ref{fig:overlap_DoS_free_electron_fcc}.
%
\begin{figure}
  %% how to generate this plot:
  %%  set DoS = true in overlap.cxx test_fcc
  %% 	run -t overlap. and set Ref = true   and nmax high for the analytical reference
  %% 	run -t overlap. and set Ref = false  and scan through nmax from 0..9
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/overlap_DoS_free_electron_fcc} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:overlap_DoS_free_electron_fcc}
  \caption{
	Integrated density of states of the free electron gas. The analytical solution is shown in red
	whereas the black lines show the \ac{sho} basis result up to $\nu\um{max} = 9$.
% 	and $\sigma = 1.2$ Bohr while the FCC lattice constant is $8$ Bohr. // ToDo: check sigma and alat
  }
\end{figure}
%
%
\begin{figure}
  %% how to generate these plots: tests/free_electron.sh
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=.7\textwidth]{fig/free_electron_sc} %%
	\includegraphics[width=.7\textwidth]{fig/free_electron_bcc} %%
	\includegraphics[width=.7\textwidth]{fig/free_electron_fcc} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:overlap_DoS_free_electron_cubic_lattices}
  \caption{
	Integrated density of states of the free electron gas. The analytical solution is shown in red
	whereas the black lines show the \ac{sho} basis result up to $\nu\um{max} = 9$ 
	for cubic lattice structures SC, BCC, FCC (top to bottom).
  }
\end{figure}
%
%
\section{All electron calculations}\label{sec:all-electron}
%
\begin{figure}
  %% how to generate this plot:
  %% 	run -t atom_core.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/atom_core_LDA_dots} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:atom_core_levels}
  \caption{
	Eigenenergies of self-consistent neutral isolated spherical spin-paired atom calculations with LDA.
  }
\end{figure}
%
%

\section{Exact Poisson solver}
%
% \begin{figure}
%   %% how to generate this plot:
%   %% 	run -t atom_core.
%   \begin{minipage}[c]{.990\textwidth}
% 	\includegraphics[width=\textwidth]{fig/fourier_poisson} %%
%   \end{minipage}\hfill
%   \begin{minipage}[c]{.009\textwidth}
%   \end{minipage}
%   \label{fig:fourier_poisson_solver}
%   \caption{
% 	Comparison of input and output of the (3D periodic) \ttt{fourier\_poisson.}-solver with (isolated 1D) radial solutions.
% 	Differences might stem from the different boundary conditions.
%   }
% \end{figure}
%
%
A Poisson solver based on Fourier-transforms (FFT by Intel Math Kernel Library)
is implemented to be able to exclude artifacts from e.g.~iterative Poisson solvers
when developing other modules of the code. 
It serves also as a reference to estimate the precision of other Poisson solvers
as the treatment in reciprocal space is analytically exact.


\section{Live Atoms}\label{sec:live_atoms}
%
\begin{figure}
  %% how to generate this plot:
  %% 	run -t single_atom.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/single_atom_Cu_smooth_partial_waves_order3} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:single_atom_Cu}
  \caption{
	True wave functions for core states and valence states, 
	smooth pseudized wave functions for valence states of copper.
  }
\end{figure}
%
%
The module \ttt{single\_atom.} starts from a self-consistent calculation by loading 
\ttt{pot/Zeff.00}$Z$ where $Z$ is the atomic number.
The files store $Z\um{eff}(r)$ i.e.~the screening of the nuclear charge.
It can be converted to the self-consistent spherical true potential
\begin{equation}
	V\um{tru}(r) = -\frac{Z\um{eff}(r)}{r}
\end{equation}
however, the core solver used \ttt{atom\_core.} takes $rV(r)$ as input so
we only need to modify the sign.
The advantage of storing $Z\um{eff}$ is that the numbers stay in a regular range
and users can distinguish files simply by looking at the \ttt{head} of the file.
%
\begin{figure}
  %% how to generate this plot:
  %% 	run -t single_atom.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/RamerDouglasPeucker_reduction} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:RamerDouglasPeucker_reduction}
  \caption{
	Applying algorithms from vector graphics allows to sparsify and reduce 
	the file sizes for input data.
  }
\end{figure}
%
When storing $Z(r)$ instead of $rV(r)$ typically all numbers are positive 
which facilitates plotting on a log scale.
This way of representation also allows for data compression of the files:
$Z\um{eff}(r)$ is a monotonously falling function from $Z$ at the origin to $q$ at the
end of the radial grid (assume that atom has total charge $q$).
It is sampled on the same grid that is used to solve for core and valence states,
i.e.~it often features more than 2000 radial grid points.
Using the sparsification method for path data by Ramer/Douglas and Peucker,
we can reduce the number of radial support points below 500 (1000) points while
the deviations are not larger than $10^{-6}$ ($10^{-11}$), 
c.f.~fig.~\ref{fig:RamerDouglasPeucker_reduction}.


From the self-consistent spherical potential, we compute the eigenenergies
of all occupied atomic eigenstates.
Then, we distinguish which of those are to be considered as valence states, 
typically by an energy criterion, e.g.~\unit[1]{Ha} below zero.

The module has an update function which then envokes updates on the following parts
\begin{itemize}
 \item true core states from true spherical potential
 \item true core density from core occupations, mix with previous
 \item smooth core density
 \item energy parameters and true partial waves
 \item smooth partial waves
 \item charge deficit tensor
 \item density matrix from valence occupations (isolated mode only)
 \item density tensor from density matrix
 \item true and smooth density from density tensor
 \item compensation charges from density tensor
 \item smooth augmented density from smooth density and compensators
 \item true and smooth potential from corresponding densities
 \item zero potential $\bar V$ by parabola matching
 \item extract spherical potentials, mix with previous
 \item matrix elements for atomic Hamiltonian and overlap operator 
		from potentials and corresponding partial waves
\end{itemize}

This workflow can be iterated to let the atomic data relax.
In the isolated mode, the energy parameters for the true partial waves are chosen as valence eigenenergies
and the density matrix is prepared to represent spherically symmetrized valence occupations.
Then, it can be verified that the self-consistent potential that was input is
not changing any more when iterated in the \ttt{single\_atom.} update cycle.

In full operation, density matrix, energy parameters and electrostatic multipoles
are input from outside and only atomic Hamiltonian correction, projector functions
and charge deficit matrix for the atomic overlap operator are output. 




\section{Spherical Atoms}\label{sec:spherial-atoms}
%
The \ttt{spherical\_atoms.} mode aims to
make a cheap module to find the initial
charge density of very large calculations.
It is based on LiveAtoms (see sec.~\ref{sec:live_atoms})
and their isolated mode, i.e.~the density matrix is generated from valence occupation numbers.
Currently, the atomic densities and potentials are restricted to
stay spherical (only $\ell = 0$ terms) so
also the valence occupation numbers are averaged whithin the shells.
This constraint could be relased in the future.

The atoms export a smooth density (currently only a spherical core density, 
therefore also valence states need to be treated as core states)
which is brought to a 3D grid.
There, we evaluate the exchange-correlation potential and, after adding 
appropriate charge compensators, also the electrostatic potential.
The Poisson equation is so far solved using FFTs but this will be
replaced by a multi-grid accelerated iterative Poisson solver based on a
high-order finite-difference Laplacian since this is more flexible
in terms of boundary conditions and scalability.
Then, the 3D smooth effective potential is projected to a radial basis
for each atom center and these potentials are fed back into the LiveAtom module.

Probably, we should make an intermediate module that takes care of
valence treatment of single atoms on coarse radial grids with an artificial confinement potential.
This would then be able to capture $m$-resolution.

With the spherical constraint as-is,
we could let the valence occupation numbers relax 
in order to get the initial charge transfer right.
For this, only the height of the smooth effective potential at
the position of each atom needs to be communicated to the LiveAtom objects.
It can be done by the $v^a_{00}$ term which is found by projection 
$\braket{\hat n^a_{00}}{V\um{es}(\vec r)}$.



\subsection{On the shape of compensators}\label{sec:compensator-radii}
In order to get $v^a_{00}$ correct, we have to assume that there is no overlap
between charge compensation densities of two different atoms
which leads to very localized compensators.
The GPAW choice $r\um{aug}/\sqrt{10}$ leads to only a fraction of $1.7\cdot 10^{-4}$ of the total charge of the compensator
outside of $r\um{aug}$ which is probably a good compromise in terms of accuracy and cost.
With a typical $r\um{aug} =$\unit[2]{Bohr}, the compensation charge shapes
$\exp(-10\frac{r^2}{r\um{aug}^2}) = \exp(-\frac{r^2}{2 \sigma^2})$
has $\sigma = r\um{aug}/\sqrt{20} = $\unit[0.447]{Bohr}.
The corresponding grid cutoffs are $3\sigma^{-2} = $\unit[15]{Rydberg}
which requires a grid spacing of at most \unit[0.811]{Bohr}.
For first row elements, the augmentation radii can be 
of the order of 1.0 and even \unit[0.9]{Bohr} for hydrogen.
So the max.~grid spacing would be \unit[.365]{Bohr}.
In order to be accurate enough, we would like to
keep the density grids at a grid spacing of \unit[.236]{Bohr}
so that there are $8^3$ grid points in one \AA$^3$.


%
\begin{figure}
  %% how to generate this plot:
  %% 	run -t single_atom.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/larger_compensation_radii} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:larger_compensation_radii}
  \caption{
	Increasing the $r\um{cut}$ of the compensation charge densities
	to $2\times$, $3\times$ and $4\times$ the typical $r\um{aug}/\sqrt{10}$
	used by GPAW shows that the zero potential $\bar V$ becomes much smoother
	and even attractive (here shown for aluminum, $r\um{aug} =$ \unit[2]{Bohr}).
  }
\end{figure}
%
%
In the spirit of Ewald's method we could make the compensation charges
softer, i.e.~allow a larger radius. However, then we need correction
potentials.
In PAW, the potential contribution $\bar V$ is added only inside the sphere.
Figure \ref{fig:larger_compensation_radii} shows that $\bar V$ extends beyond
$r\um{aug}$ if we increase $r\um{cut}$.
We probably have to consider to have two different corrections:
The traditional localized $\bar V$ which fills the potential well inside the sphere
and a new correction for extended very smooth compensators.
The, the latter is added after solving the Poisson equation.
After adding, we can make the projection with the more localized compensation charges.
And then add the traditional $\bar V$ to get to the effective potential.

\subsection{The zero potential}

In order to reproduce the exact total effective potential outside 
%
\begin{figure}
   %%% how to reproduce this:
   %%% git key 9f115f160f63d6cf7df64cf60de547293d8d5ca6 
   %%% make -j && ./aa3 -t spherical_atoms. +verbosity=11  +single_atom.echo=6 > out
   %%% and rune once again with
   %%% manipulated prefactor (e.g. insert 0 instead of Y00 in spherical_atoms.cxx:343)
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/20200131_zero_potential_inset_times_r} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:zero_potential}
  \caption{
	Radial projection of the effective potential $V\um{tot} = V\um{xc} + V\um{es}$
	Before adding the localized spherical atom contributions $\bar V^{a}$,
	a strong potential dip can be seen at the positions of the two atoms Al and P in a dimer.
	Furthermore, there is a faint dip around \unit[4]{Bohr} which indicates the position of the other atom, 
	see inset. For better visibility, the inset shows $r\,V(r)$.
  }
\end{figure}
%
%


\subsection{Communicating the potential shifts}\label{sec:multipole-shifts}
Different spheres in the PAW framework communicate via the electrostatic
potential which is to be evaluated in 3D for the smooth quantities
and inside the spheres for both, smooth and true quantities on radial grids.
The charge deficits $q^a_{\ell m}$ inside each sphere are
brought to the 3D grid with the help of localized smooth compensator charge densities 
(see sec.~\ref{sec:compensator-radii}).
%
\begin{figure}
  %% how to generate this plot:
  %% 	run -t spherical_atoms.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/finding_electrostatic_multipole_shifts} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:multipole-shifts}
  \caption{Smooth electrostatic potentials of an A$-$B dimer with ionization, here Al$^+ -$P$^-$.
  In the radial representation, the electrostatic problem is first solved disregarding boundary conditions (dotted lines).
  Then, the radial solutions are shifted to match $v_{\ell m}$ as found by projection with the compensator shapes.
  The shifted radial solutions (solid lines) and a Bessel projection of the 3D solution match inside the spheres (radii 2 Bohr).}
\end{figure}
%
%
After solving for the 3D electrostatic potential $\tilde V\um{es}(\vec r)$,
we can probe the value and derivatives of the potential at the nuclear site, $V\um{es}(\vec R^a)$,
however, in order to avoid egg-box effects we
probe by a projection to the charge compensator shape:
$$ v^a_{\ell m} = \int d^3 \vec r \  \hat g_{\ell m}(\vec r) \tilde V\um{es}(\vec r) $$
See fig.~\ref{fig:_} for an example.

\begin{figure}
  %% how to generate this plot:
  %% 	run -t spherical_atoms. +spherical_atoms.test.ion=.0 +spherical_atoms.max.scf=19 +single_atom.echo=9
  %% 	run -t spherical_atoms. +spherical_atoms.test.ion=.9 +spherical_atoms.max.scf=19 +single_atom.echo=9
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/20200127_spherical_atoms_ionized0} %%
	\includegraphics[width=\textwidth]{fig/20200127_spherical_atoms_ionized9} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:ionized-spherical-atoms-AlP-dimer}
  \caption{
   Smooth electrostatic potentials of an Al$-$P dimer 
   without ionization (upper panel) and ionized Al$^{+.9}$P$^{-.9}$ (lower panel).
   Ionization shifts the potential value at the origin down for Al (by \unit[-67.9]{mHa} or \unit[-1.85]{eV})
   and up for P (by \unit[54.3]{mHa} or \unit[1.47]{eV}).
   %%% how to find this value?
   %%% for Al grep '0.000100923'  20200127_spherical_atoms_ionized*.agr
   %%% for P  grep '0.000101042'  20200127_spherical_atoms_ionized*.agr
    %%% the first column here is V(r) and the seconds is the projected V(xyz)
	% # for Al
	% 20200127_spherical_atoms_ionized0.agr:0.000100923 -2.34213 -2.33898
	% 20200127_spherical_atoms_ionized9.agr:0.000100923 -2.41004 -2.40433
	% # for P
	% 20200127_spherical_atoms_ionized0.agr:0.000101042 -3.07102 -3.0669
	% 20200127_spherical_atoms_ionized9.agr:0.000101042 -3.01669 -3.01555
   }
\end{figure}



\section{Linear Scaling}\label{sec:linear-scaling}
%
A first glimpse of linear scaling algorithms can be found in the
\ttt{geometry\_analysis.} module.
Here, all target atoms in the vicinity of $r\um{vic} = \unit[6.144]{\AA}$ around each source atoms
have to be found in order to analyse its local bond structure
and coordination number.
A naive implementation leads to an $N\um{atoms}^2$-scaling algorithm,
in fact, the distance of $n\um{images} \cdot N\um{atoms}^2$ atom-atom pairs
needs to be visited.
Although we can compare the squared distance to the squared radius of the vicinity,
hence omitting the computation of the sqaure root, the cost prefactor
is in the range of one nanosecond on a single core CPU.
For example the CPU runtimes shown in fig.~\ref{fig:geometry-analysis-scaling}
are $t \approx n\um{images} \cdot N\um{atoms}^2 \cdot \unit[1.78]{ns}$, c.f.~red data points.
%%%% 27*1e6^2 atom-atom pairs in 48116.43 sec
\\
A linear scaling algorithm that produces the same output comes at the additional
cost of an initial grouping operation of the atomic positions into clusters.
However, as we know the spatial position and max.~extend of the clusters,
it is simple to analyze only atom pairs where the clusters of both partners
are not too remote.
A simple treatment in 3D is to generate uniform rectangular boxes. 
The min.~box extend is $r\um{vic}$.
Periodic images of boxes need to be taken into account.
If the simulation cell is large, a halo thickness of 1 needs is sufficient.
The initial (linear scaling) operation is to generate lists of those atoms
that are located inside each box.
%
\begin{figure}
  %% how to generate this plot:
  %%    rm -f atoms.xyz && ln -s gst_set128.xyz ./atoms.xyz
  %% 	time run -t geometry_analysis.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/geometry_analysis-scaling} %% .agr .pdf
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:geometry-analysis-scaling}
  \caption{
  Linear scaling vs.~quadratic scaling can be observed when computing atom-atom distances.
  The dashed lines have slope 1 and 2, respectively, fitted through a single data point.
  The crossover of the dashed lines happens around $13$ atoms 
  whereas the measured data (circles) cross around $32$ atoms.
  }
\end{figure}
%
%
This solution leads to a time requirement $t \approx N\um{atoms} \cdot \unit[633]{ns}$.
% Comparing these prefactors
% we can extrapolate a theoretical crossover for this particular case (bulk, cubic cell) around $13$ atoms.
% For any larger number of atoms, the linear scaling solution is faster.

\section{SHO Projectors}

%
\begin{figure}
  %% how to generate this plot:
  %%    assert(echo_prj);
  %% 	time run -t single_atom.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/sho_radial} %% .agr .pdf
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:sho-radial-projectors}
  \caption{
  Radial projectors for $\sigma = \unit[0.5]{Bohr}$ and $\nu\um{max} = 3$.
  }
\end{figure}
%
%
A set of $6$ radial \ac{sho}-projectors is shown in fig.~\ref{fig:sho-radial-projectors}.
With the multiplicity of the spherical harmonics ($2\ell$+$1$) this leads to 
$$2 \times 1 + 2 \times 3 + 1 \times 5 + 1 \times 7 = 20$$
projectors when exanded on the 3D grid.
However, the expansion happens in the factorizable representation of the
\ac{sho}-eigenstates: all products of the Hermite polynomials 
$H_{n_x}(x) \cdot H_{n_y}(y) \cdot H_{n_z}(z)$ 
times a Gaussian envelope function $\exp(-\frac12 r^2)$
for which $n_x + n_y + n_z \leq \nu\um{max}$ span the same function space
as radial \ac{sho}-eigenfunctions functions times spherical harmonics.
The factorizable representation comes with the advantage that the 1D functions,
e.g.~$H_{n_x}(x) \cdot \exp(-\frac 12 x^2)$ can be evaluated on-the-fly 
at affordable costs~\cite{BaumeisterTsukamotoPASC19}.

\subsection{Normalization}
In the factorizable representation, one could infer L2-normalization of each 1D projector. 
However, this involves several \ttt{sqrt}-operations and divisions which can be avoided
by applying scaling factors such as normalizations in
after the projection or in advance of the addition operation.
The recursive definition of the Hermite polyomials is
\begin{equation}
	H_{\nu + 1}(x) = x H_{\nu} - \frac{\nu}{2} H_{\nu - 1}
\end{equation}
where $\nu$ is $n_x$, $n_y$ or $n_z$, respectively.
(compare \ttt{hermite\_polynomial.hxx}) 
With that and the decay factor $\exp\left({-\frac{x^2}{2\sigma^2}}\right)$
for each vector component $x$, $y$ and $z$
we find that 1D Hermite-Gauss projectors are L2-normalized by a prefactor
\begin{equation}
	f_{\nu} = \sqrt{ \frac{2^{\nu}} {\sqrt{\pi} \sigma \nu!} }
\end{equation}
And, hence, the 3D Cartesian factorizable projectors are L2-normalized by the prefactor
\begin{equation}
	f_{n_x n_y n_z} = \sqrt{ \frac{2^{n_x + n_y + n_z}} {\sqrt{\pi^3} \sigma^3 n_x! n_y! n_z!} }
\end{equation}


\subsection{Normalization for electrostatic}
For the preparation of neutral charge distributions despite charge deficits in the core and the partial waves
compensator charges $\hat q_{\ell m}(\vec r)$ are used.
These also follow the Gaussian shape function %% reference needed, e.g. GPAW (but GPAW usues \exp(-\frac{\vec r^2} {r_c^2})
\begin{equation}
 \hat q_{\ell m}(\vec r) = f_{\ell} \exp(-\frac{\vec r^2} {2\sigma^2}) Y_{\ell m}(\hat{\vec r}) |\vec r|^\ell
\end{equation}
which makes it suitable to use the projection and addition routines for factorizable projectors,
although we do not require any contributions with $\nrn > 0$.
Different from the L2-normalization, the L1-normalization factor $f_\ell$ for electrostatics is determined by
\begin{align}
 1 &= \int \mathrm d^3\vec r  \  \hat q_{\ell m}(\vec r) Y^*_{\ell m}(\hat{\vec r}) |\vec r|^\ell \\
 f_\ell^{-1} &= \int\limits_0^\infty \mathrm d r r^2 \exp(-\frac{r^2} {2\sigma^2}) r^{2\ell} \\
 f_\ell^{-1} &= \sigma^{2\ell + 3} \int\limits_0^\infty \mathrm d x \exp(-\frac{x^2}{2}) x^{2\ell + 2} \\
 f_\ell^{-1} &= \sigma^{2\ell + 3} (2\ell + 1)!! \sqrt{\frac{\pi}{2}} \\
 f_\ell &= \frac{\sqrt{2}}{\sqrt{\pi} \sigma^{2\ell + 3} (2\ell + 1)!!}
\end{align}
where we used that $\int\limits_0^{\infty} x^{2m} \exp(-x^2/2) \mathrm dx  = \sqrt{\pi/2} (2m-1)!!$ for $m \in \mathbb N_0$.
See \ttt{sho\_projection::radial\_L1\_prefactor} for an implementation of $f_\ell$.

Before we use the unitary SHO transform from Cartesian to radial,
Cartesian coefficients need to be normalized.
After transformation, we have to see that also the radial SHO eigenfunctions are L2-normalized.
For $\nrn = 0$ the Laguerre polynomial is a constant only, so
the radial L2-normalization is given by
\begin{align}
	f^{-2}_{L2} &= \int\limits_0^\infty \mathrm dr r^2 \left( r^\ell \exp(-\frac{r^2}{2\sigma^2}) \right)^2 \\
				&= \sigma^{2\ell + 3} \int\limits_0^\infty \mathrm dx x^{2\ell + 2} \exp(-x^2) \\
				&= \sigma^{2\ell + 3} (2\ell + 1)!! \frac{\sqrt{\pi}}{2^{2+\ell}} \\
\end{align}
See \ttt{sho\_projection::radial\_L2\_prefactor} for an implementation of $f_{L2}$ as a function of $\ell$.
However, we need the (L1-)normalization described above, so we introduce a proper re-scaling factor.

\subsection{Masks for localized functions}
%
Certain functions other than the projectors 
need to be brought to the Cartesian grid.
This is in particular 
the smooth core density $\tilde n\um{c}(|\vec r - \vec R^a|)$ and 
the localized zero-potential  $\bar v^a(|\vec r - \vec R^a|)$.
The transfer happens using \ttt{real\_space\_grid::add\_function}
which requires an $r^2$-grid, i.e.~$r_i = \sqrt{i/a_{r^2}}$ and
the lower index $i$ needed for linear interpolation is found as
$$ i = \lfloor a_{r^2} r^2 \rfloor $$
A typical value for $a_{r^2}$ is $16.0$

\begin{figure} [ht]
  \centering
  %% how to generate this plot: ~/runfort zam044:~/Codes/a43/doc/fig/plot/mask.F90
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/polynomial_mask_function} %% .agr .pdf
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \caption{Mask function applied after Bessel filtering.
  For $r < R$, the mask (black solid line) follows $(1 - (r/R)^{16})^8$ 
  and connects smoothly to zero at $R$, in this illustration $R = 10$.
  The first 9 grid points of an $r^2$-grid with $a_{r^2}=16$ are shown with a + mark.
  } \label{fig:mask_function}
\end{figure}


\clearpage

\section{Implementation of the PAW formalism} \label{sec:paw-theory}
%
Various ways of implementing the \ac{paw} formalism can be found in the literature.
While all of these should formally lead to the same results,
their rates of convergence and the complexity of implementation may differ.
For example Kang \emph{et al.}~ \cite{Kang2016}
follows closely to the descriptions of GPAW \cite{Rostgaard-paw-note}
where the expressions for the total energy and Hamiltonian are derived
in terms of many precomputed single terms.
For instance the atom-centered corrections to the total energy
involve a rank-4 tensor that reads
\begin{equation}
	\iint \m dr \ \m dr' \   \frac{ \phi_i(r) \phi_j(r) \phi_k(r') \phi_l(r') }{\vec r - \vec r'}
\end{equation}
and a similar but negative contribution with $\tilde \phi$ instead of $\phi$.

As in usual \ac{paw} implementations partial waves are constant 
and only read from files at initialization, this way of implementing \ac{paw}
is a good choice when it comes to clarity of the formalism.
As we intent to let core states relax and partial waves adopt
to the chemical environment,
an alternative way is outlined in the following sections.
But first, a short review of the \ac{paw} method is given.

\subsection{PAW method}
%
\subsubsection{Total energy}
%
The total energy consists of smooth contributions ($\tilde{\phantom{x}}$) from the 3D basis
representing the entire simulation volume and corrections from the atomic spheres
which are evaluated on radial grids.
\begin{align}
	E\um{tot} &= \tilde E + \sum_a \left( E^a - \tilde E^a \right) \\
	\tilde E  &= \tilde T\um{valence} + E\um{xc}[\tilde n] + E\um{es}[\tilde\varrho] + \braket{\tilde n\um{valence}}{\bar V}
\end{align}
where $\tilde T$ denotes the kinetic energy of the smooth parts of the occupied Kohn-Sham eigenstates.
$\tilde n$ is the smooth valence density $\tilde n\um{valence}$ plus smooth core density contributions $\tilde n^a\um{c}$
and $\tilde\varrho$ is a smooth charge density that includes compensation charges $\tilde g_{\ell m}^a$
that make up for the charge deficit and smear out the core charge such that it is in total neutral
for a system with equal number of electrons and protons.
$\bar{V}$ is the sum of all \emph{zero}-potential contributions $\bar v^a$ localized inside
each augmentation sphere. The notation $\braket{\cdot}{\cdot}$ has been used here to 
abbreviate a spatial integral.

The electrostatic contribution is quadratic in the augmentation density $\tilde\varrho$, 
i.e.~
\begin{align}
E\um{es}[\tilde\varrho] &= \frac{1}{2} \braket{\tilde\varrho}{V\um{es}[\tilde\varrho]}
\end{align}
where we can exploit that the 3D Poisson equation $\Delta V\um{es}[\tilde\varrho](\vec r) = -4\pi\tilde\varrho(\vec r)$ only needs to be solved once.

The atom-centered corrections to the total energy read
\begin{align}
  E^a &= T^a\um{core} + \sum_{ij} \rho^a_{ij} \braketop{\phi^a_i}{\hat T}{\phi^a_j} \\
      &+ E\um{xc}[n^a] \\
      &+ \frac{1}{2} \braket{ n^a }{ V\um{es}[n^a] } - Z^a \braket{ n^a }{ \frac{1}{r} } 
      \label{eqn:total-energy-true-atom-corrections}
\end{align}
So we can label the term as kinetic energy of the core electrons, 
kinetic energy of the true valence partial waves,
exchange-correlation energy of the true atom-centered density,
Hartree and Coulomb energy of the atom-centered density.

For the smooth corrections, we find
\begin{align}
  \tilde E^a &= \sum_{ij} \rho^a_{ij} \braketop{\tilde\phi^a_i}{\hat T}{\tilde\phi^a_j} \\
      &+ E\um{xc}[\tilde n^a] \\
      &+ \frac{1}{2} \braket{ \tilde\varrho^a }{ V\um{es}[\tilde\varrho^a]      }
      \label{trm:electrostatic-energy-smooth-atom-correction} \\
      &+ \braket{ \tilde n^a\um{valence} }{ \bar v^a } 
\end{align}
The labels differ slightly from those in eq.~(\ref{eqn:total-energy-true-atom-corrections}):
kinetic energy of the smooth valence partial waves,
exchange-correlation energy of the smooth atom-centered density,
electrostatic energy of the atom-centered augmented density.
Furthermore, there is a correction term that accounts for the zero-potential.

\subsubsection{Hamiltonian}
%
The Hamiltonian is found by variation of the total energy w.r.t.~$\tilde \Psi(\vec r)$
and, applying the chain rule, 
by variation of the atom-centered energy contributions w.r.t.~$\rho^a_{ij}$.
%
The Hamiltonian reads
\begin{align}
  \hat H &= \hat T + \tilde V\um{eff}(\vec r) + \sum_{aij} \ket{p^a_i} \left( H^a_{ij} - \tilde H^a_{ij} \right)
  \bra{p^a_j}
\end{align}
where the local effective potential consists of the following
\begin{align}
  \tilde V\um{eff}(\vec r) = V\um{es}[\tilde\varrho](\vec r) + V\um{xc}[\tilde n](\vec r) + \bar V(\vec r)
\end{align}
The localized zero-potentials are $\bar V(\vec r) = \sum_a \bar v^a(\vec r - \vec R^a)$.
The non-local contributions read
\begin{align}
	H^a_{ij} &= \braketop{ \phi^a_i }{ \hat T }{ \phi^a_j } \\
	         &+ \braketop{ \phi^a_i }{ V\um{xc}[n^a] + V\um{es}[n^a] - \frac{Z^a}{r} }{ \phi^a_j } 
	         \label{eqn:hamiltonian-true-atom-potential-part} \\
	\tilde H^a_{ij} &= \braketop{ \tilde\phi^a_i }{ \hat T }{ \tilde\phi^a_j } \\
	         &+ \braketop{ \tilde\phi^a_i }{ V\um{xc}[\tilde n^a] + V\um{es}[\tilde\varrho^a] - \bar v^a(r) }{ \tilde\phi^a_j }
	         \label{eqn:hamiltonian-smooth-atom-potential-part}
\end{align}
Due to the non-linearity of $V\um{xc}$ the evaluation of the \ac{xc} parts of atom-centered potential matrix elements
(term~(\ref{eqn:hamiltonian-true-atom-potential-part}) and (\ref{eqn:hamiltonian-smooth-atom-potential-part}))
can only be performed numerically.
Implementations like GPAW \cite{GPAW,Rostgaard-paw-note} and ACE-Molecule \cite{Kang2016}
decompose the linear and quadratic contributions of $\rho^a_{ij}$ with precomputed tensors
which are constant over the course of the calculation, even when updating the atomic position.
If, however, we let the core state relax, the core density changes slightly in every SCF iteration
and we can construct a new true reference potential from which we generate new partial waves.
Then the approach of evaluating the entire terms~(\ref{eqn:hamiltonian-true-atom-potential-part}) and (\ref{eqn:hamiltonian-smooth-atom-potential-part}) numerically does not lead to modest extra costs, 
in fact, only the solution of the electrostatic problem in radial representation. 
Note that during the construction of electrostatic potentials inside the augmentations sphere,
i.e.~$V\um{es}[n^a - Z^a \delta]$ and $V\um{es}[\tilde\varrho^a]$, the boundary conditions on the augmentation sphere must match between
the two and also with the electrostatic potential on the 3D grid, $V\um{es}[\tilde\varrho]$.
This is achieved comparing the projection coefficients $\braket{\hat g^a_{\ell m}}{V\um{es}[\tilde\varrho]}$ to $\braket{\hat g^a_{\ell m}}{V\um{es}[\tilde\varrho^a]}$ and adding correcting multipole shifts to $V\um{es}[\tilde\varrho^a]$ and $V\um{es}[n^a - Z^a\delta]$.

The \emph{intelligent zero} inserted to make the local potential smoother inside the augmentation sphere
leads to the term $\bar v^a$. In fact, the electrostatic potential will feature a smooth but deep potential well
at the position of the nucleus. $\bar v^a$ is chosen to fill the well.
Different from other implementations of \ac{paw} we add only the contribution of the valence density
with $\bar V$ to the total energy and subtract it in the atom corrections.
The reason behind this is that there will be tails of the core densities $n^{a'}\um{c}$
of neighboring atoms that give contributions which are not cancelled in the atom-centered treatment.
A similar error in the total energy might appear from the \ac{xc} contribution.


In the evaluation of $E\um{es}[\tilde\varrho]$, 
we find that $\tilde\varrho(\vec r)$ is relatively smooth in the interstitial region
and has mostly strong negative value inside the augmentation sphere. 
The negative values represent the smeared out proton density.
The resulting $V\um{es}(\vec r)$ also has large negative values in the augmentation region.
Hence, the augmentation region leads to a large positive contribution to the
electrostatic energy with does not change, except when atoms move.
It should be investigated if the electrostatic total energy contribution should
better be evaluated as
\begin{align}
  E\um{es} = \frac{1}{2} \braket{ \tilde n }{ V\um{es}[\tilde\varrho] } 
\end{align}
with corresponding change in the atom-centered correction term~(\ref{trm:electrostatic-energy-smooth-atom-correction}).
This is along the line of evaluating the nuclear repulsion energy
\begin{align}
  E_{ZZ} = \frac{1}{2} \sum_{i, j \neq i} \frac{Z_i Z_j}{|\vec R_i - \vec R_j|}
\end{align}
where also the case $j = i$ is excluded (although due to a divergent expression).

%% Some thoughts on the single_atom module
%% in isolation, we so far have the possibility not to transfer the
%% occupation numbers from the core to the valence band.
%% With all states treated as core state we get the same results
%% as the module atom_core, 
%% 			in fact, we could consider to make single atom
%% 			so versatile as to replace atom_core...
%% Now for the full DFT calculation, we typically need a start
%% density. Currently, potential_generator and the single_atom::[atom_update]
%% interface support the setup of a superposition of spherical atom centered
%% valence densities which are generated from the occupation numbers marked as
%% valence. If we have this spherical_valence_density, we need to account for
%% its charge deficit in the qlm's to get the system neutral.
%% or, we could have a rough number be integrating the r^2-grid
%% the computing the 3D spatial integral and adding to q_00 

%% maybe, we can also incorporate the spherical_valence_density
%% into the workflow of computing a reference atom energy.
%% The reference atom energy is subtracted from the all-electron total energy
%% in order to work with smaller numbers.
%% We have to see if we need to confine the spherical potential artificially
%% e.g. in the situation of ionization with additional electrons.
%% The reference calculation would have 
%% 		a) the same potential as the all-electron calculation but then, 
%%         potential and density do not belong to each other. 
%% 		b) each have their own potential

%% -t atom_core.
%% # scf_atom  Z=29  E_tot= -1651.876238543 Ha
%% # scf_atom  Z=29  E_kin= 1675.060063566 E_xc= -64.646370807 E_es= -3262.289931302 Ha
%% # scf_atom  Z=29  E_Coulomb= -3974.589211915 E_Hartree= 712.299280613 Ha

%% # scf_atom  Z=111  E_tot= -44246.825520079 Ha
%% # scf_atom  Z=111  E_kin= 52503.526768673 E_xc= -632.297804761 E_es= -96118.054483991 Ha
%% # scf_atom  Z=111  E_Coulomb= -112339.247198631 E_Hartree= 16221.192714640 Ha

%% # scf_atom  Z=120  converged in 5 iterations to res=0.0e+00, E_tot= -54020.644039128 Ha
%% # scf_atom  Z=120  E_kin= 65862.495581050 E_xc= -724.329328545 E_es= -119158.810291632 Ha
%% # scf_atom  Z=120  E_Coulomb= -138447.053311611 E_Hartree= 19288.243019978 Ha

%                  energies[E_eig] = eigenvalue_sum;
%                  energies[E_kin] = energies[E_eig] - energies[E_Htr]*2
%                                  - energies[E_Cou] - energies[E_vxc]; // total kinetic energy
%                  energies[E_est] = energies[E_Htr] + energies[E_Cou]; // total electrostatic energy
%                  energies[E_tot] = energies[E_eig] - energies[E_Htr]
%                                  + energies[E_exc] - energies[E_vxc]; // total energy

% eigenvalue_sum = \sum_n f_n \epsilon_n
% energies[E_Htr] = 1/2 \int (4\pi) r dr r*V_es[n] n(r)
% energies[E_Cou] =  -Z \int (4\pi) r dr n(r)

%% In any case, huge energy contributions stem from the core.
%% In the open situation with an extended valence density,
%% and partial waves which are not based on eigenstates (i.e. arbitrary energy parameters)
%% we cannot compute a total energy for the single atom.
%% We could try to find, for each ell (and spin)-channel separately,
%% valence occupation numbers such that the charge inside the augmentation
%% sphere is the same. This would then give us an atomic reference density 
%% which should cancel most of the strong energy contributions.
%% Do we know the ell-resolved charge inside the sphere?
%% Yes, sum the diagonal values of the atomic density matrix that 
%% have the same spin, needs renormalization.
%% Then, we can construct an eigenvalue sum with the newly found
%% occupation numbers f_n and the eigenvalues \epsilon_n of the spherical valence states.
%% For the Hartree energy, we can form the integral between the spherical component
%% of the true electrostatic potential and the new density. How about the shifts?
%% The Coulomb energy is only a function of the new density.
%% Restrict the integrals to the sphere and reduce the eigenvalue sum by the part
%% of charge inside the sphere.
%% How about the XC contributions?

%% Alternative (simple):
%% we run -t atom_core. +atom_core.test.Z=0 +atom_core.test.Z.inc=1 +atom_core.test.Z.end=120
%% (actually, we could go up to 121 here)
%% and fit, the converged E_tot values:
% E_tot = a0 * Z^a1
%	a0 = -0.345969
%	a1 = 2.49667
%
%Chi-square: 1.1103e+06
%Correlation coefficient: 0.999984
%Theil U coefficent: 0.00443971
%%
%%
%% or E_tot = -0.340771 * Z^2.5  (Chi-square: 1.202e+06)
%% with the polynomial correction term a0*Z^2 + a1^4 + a2*Z^6 + a3*Z^8
%	a0 = -0.150467
%	a1 = 4.78291e-05
%	a2 = -4.25187e-09
%	a3 = 1.09394e-13
%% brings us to deviation at most 25 Ha

%% or with a simple sum_{i=0}^3 a_i Z^{2i + 2}
%Computed values:
%	a0 = -1.88044
%	a1 = -0.000262094
%	a2 = 1.53592e-08
%	a3 = -4.31997e-13
%
%Chi-square: 446563
%Correlation coefficient: 0.999994
%Theil U coefficent: 0.00274541


%% We could do the same to all components of the total energy ...


% ==============================================================================
\bibliographystyle{splncs03} \bibliography{literature}
% ==============================================================================

\end{document}
