\documentclass[oribibl]{llncs}

\usepackage{units}
\usepackage{psfrag} %% psfrac does not work with pdflatex
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{microtype}
\usepackage{subfigure}
\usepackage{todonotes} %% add [disable] to disable
\usepackage{transparent}
\usepackage{pgfplots}

\usepackage{acronym} %% for abbreviations
\acrodef{dft}[DFT]{density functional theory}
\acrodef{sho}[SHO]{spherical harmonic oscillator}
\acrodef{dos}[DoS]{density of states}
\acrodef{ho}[HO]{harmonic oscillator}
\acrodef{planewave}[PW]{plane wave}
\acrodef{gridpoint}[GP]{grid point}
\acrodef{paw}[PAW]{Projector Augmented Wave}


\setlength{\tabcolsep}{6pt}

\newcommand{\um}[1]{_{\mathrm{#1}}}
\newcommand{\ttt}[1]{\texttt{#1}}
\newcommand{\lmax}{\ell_{\mathrm{max}}}
\newcommand{\ellm}{L}
\newcommand{\nrn}{n_{\mathrm{r}}}
\newcommand{\ket}[1]{\left| #1 \right\rangle}
\newcommand{\bra}[1]{\left\langle #1 \right|}
\newcommand{\braket}[2]{\left\langle \left. #1 \right| #2 \right\rangle}
\newcommand{\braketop}[3]{\left\langle \left. #1 \right| #2 \left| #3 \right. \right\rangle}

\begin{document}
\pagestyle{plain}

\title       {Spherical Harmonic Oscillator Basis}
\titlerunning{Spherical Harmonic Oscillator Basis}

\author{%
  Paul F.~Baumeister\inst{1} % \and %
}

\institute{%
  J\"{u}lich Supercomputing Centre, Forschungszentrum J\"{u}lich, 52425 J\"{u}lich, Germany
%   \and Institute for Advanced Simulation, Forschungszentrum J\"{u}lich, 52425 J\"{u}lich, Germany
}

\maketitle

\begin{figure*}
	\centering
	\includegraphics[width=3cm]{fig/aa3_logo_bold_no_helper_lines} %%
\end{figure*}

% ==============================================================================
\begin{abstract}
\todo[inline]{write abstract}
\end{abstract}
% ==============================================================================


\newpage
% ==============================================================================
\section{Introduction} \label{sec:intro}
% ==============================================================================
%
Real-space grid based methods for \ac{dft}
have proven to yield good parallelizability and the same level of
accuracy as \ac{planewave} basis sets.
The latter aspect is in particular true for results converged
in terms of the number of \acp{planewave} compared to those converged
w.r.t.~the grid spacing.
However, real-space grid methods cannot be operated at very coarse
grid spacings due to unphysical interferences between the position
of atoms relative to the position of grid points.
This leads to relatively high cost prefactors (for time and space)
of the real-space methods compared to \ac{planewave} basis sets
when we want to do a fast but less accurate calcuation.
Furthermore, the iterative solver schemes applied in real-space
grid formalism often deteriorate in terms of their convergence
velocity when the number of grid points increases.
This is due to the limited width of the stencil compared to the 
global scale of the non-local solutions.
Therefore, convergence acceleration is crutial here.
In many situations, switching to a \ac{planewave} representation
is a viable option for an efficient preconditioner as
\acp{planewave} contain the full non-locality.
Then again, \acp{planewave} destroy the parallelizability
to some extend.
The approach investigated in this project is a small basis of atom-centered
localized orbitals.
This basis is not meant to produce as accurate results as \acp{gridpoint} or \acp{planewave}
or to feature a advantageous convergence w.r.t.~costs
but to be simple and cheap in its construction (low number of control parameters)
and to produce approximately right physics already at small basis sets.
If in addition we can define an efficient transformation between
representations in
the small localized basis set and grid-based representations
this basis can be used to accelerate
the congerence of a real-space grid-based method.

% ==============================================================================
\section{Spherical Harmonic Oscillator} \label{sec:sho}
% ==============================================================================
%
The quantum-mechanical \ac{ho} has the Hamiltonian
\begin{equation}
  \hat H^{[1D]}_{\sigma} = -\frac{\partial_x^2}{2} + \frac{x^2}{2 \sigma^4} \text{.}
  \label{eqn:HO-Hamiltonian}
\end{equation}
Hartree atomic units are used throughout this document.
Here, $\sigma$ is a lengthscale parameter that also fixes the scale of the eigenenergies
\begin{equation}
  E^{[1D]}_{n}(\sigma) = \sigma^{-2} \left( n + \frac 12 \right) \text{.}
  \label{eqn:HO-eigenenergy}
\end{equation}
The \ac{ho} eigenfunctions are
\begin{equation}
  \psi^{[1D]}_{n}(x) = H_n(x/\sigma) \cdot \exp\left( -\frac{x^2}{2 \sigma^2} \right) 
  \label{eqn:HO-eigenfunction}
\end{equation}
with the Hermite polynomials $H_n$.
\todo[inline]{add normalization constants}

The eigenfunctions of the quantum-mechanical 
three-dimensional isotropic harmonic oscillator 
- in the following we will refer to it as \ac{sho} -
can be written as Cartesian product of three
\ac{ho} eigenfunctions
\begin{equation}
  \hat H^{[3D]}_{\sigma} = -\frac{\vec \nabla^2}{2} + \frac{\vec r^2}{2 \sigma^{4}} 
  \label{eqn:SHO-Hamiltonian}
\end{equation}
has the solutions
\begin{equation}
  \psi^{[3D]}_{n_x n_y n_z}(x,y,z) = \psi^{[1D]}_{n_x}(x/\sigma) 
                               \cdot \psi^{[1D]}_{n_y}(y/\sigma) 
                               \cdot \psi^{[1D]}_{n_z}(z/\sigma) 
  \label{eqn:SHO-eigenfunction}
\end{equation}
and the eigenenergies
\begin{equation}
  E^{[3D]}_{n_x n_y n_z}(\sigma) = \sigma^{-2} \left( n_x + n_y + n_z + \frac 32 \right) 
  \label{eqn:SHO-eigenenergy}
\end{equation}

Furthermore, the \ac{sho} can be solved in spherical coordinates 
exploiting its spherical symmetry.
This leads to the quantum numbers $\nrn, \ell$ and $m$
and the eigenstates
\begin{equation}
  \psi_{\nrn \ell m}(r,\vartheta,\varphi) = R_{\nrn \ell}(r/\sigma) 
                               \cdot Y_{\ell m}(\vartheta,\varphi)
  \label{eqn:SHO-eigenfunction-radial}
\end{equation}
with the radial function
\begin{equation}
  R_{\nrn \ell}(r) = r^\ell \cdot L^{(\ell + \frac 12)}_{\nrn}(r^2) \cdot \exp(-\frac{r^2}2)
  \label{eqn:SHO-radial-eigenfunction}
\end{equation}
where $L_n^{(\alpha)}$ stands for the associated Laguerre polynomials.
\todo[inline]{add normalization constants}

In the code, spherical harmonics $Y_{\ell m}$ usually appear in their representation
$X_{\ell \mu}$ where each $\mu$ stands for a real-valued linear combination of $m$ and -$m$.
\todo[inline]{cite Homeier}

\begin{figure}
	%%% how to generate this plot: 
	%%% ./aa3 -t hermite_polynomial. +verbosity=10
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/hermite_gauss_functions} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:hermite_gauss_function}
  \caption{
  Hermite-Gauss functions up to $n\um{max} = 5$.
  }
\end{figure}


\subsection{SHO as a basis}
An infinite set of all \ac{sho} eigenfunctions forms a basis of the 3D function space.
Limiting the set by cut-off energy $E\um{cut} = \sigma^{-2} (\nu\um{max} + \frac 32)$
creates a finite basis.
If we create a union of finite bases centered at each atom $a$ in a \ac{dft} calculation 
we only need to choose a $\sigma$ and $\nu\um{max}$ for each atomic species.
\begin{equation}
  \chi_{a n_x n_y n_z}(x,y,z) = \psi^{[1D]}_{n_x}((x - x_a)/\sigma_a) 
                          \cdot \psi^{[1D]}_{n_y}((y - y_a)/\sigma_a) 
                          \cdot \psi^{[1D]}_{n_z}((z - z_a)/\sigma_a)
  \label{eqn:localized-basis}
\end{equation}
See fig.~\ref{fig:HO-basis-on-2-atoms}.
%
\begin{figure}
  \begin{minipage}[c]{.58\textwidth}
	\includegraphics[width=\textwidth]{fig/HO-basis-on-2-atoms} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.41\textwidth}
  
%%%% generated by fig/HO-basis-on-2-atoms.F90
%    0.082  -0.183   0.290   1.000  -0.000  -0.000
%   -0.183   0.328  -0.389  -0.000   1.000   0.000
%    0.290  -0.389   0.288  -0.000   0.000   1.000

		\begin{tabular}{r rrr}
		\toprule
				    & $\ket{s_0}$ & $\ket{p_0}$ & $\ket{d_0}$ \\
% 		\midrule
				$\bra{s_1}$  &      0.082 &  -0.183 &  0.290  \\
				$\bra{p_1}$  &     -0.183 &   0.328 & -0.389  \\
				$\bra{d_1}$  &      0.290 &  -0.389 &  0.288  \\
		\bottomrule
		\end{tabular}

  \end{minipage}
  \label{fig:HO-basis-on-2-atoms}
  \caption{
Schematic picture to illuminate the non-orthogonal localized basis in 1D.
On each atomic position \ac{ho} basis functions are centered.
Here, $\sigma$ has been chosen such that $d$-orbitals can form bonds (green lines).
The non-trivial part of the overlap matrix is shown on the right.
  }
\end{figure}
%
%

Then the evaluation of matrix elements works as follows:

\subsubsection{Overlap matrix elements}
Basis functions $\chi$ centered at the same atom $a$ are orthogonal by construction
so we only need to take care of their normalization.
We assume that an atom is positioned at $\vec R_a = \{ X_a, Y_a, Z_a \}$ or $\{ X_{1a}, X_{2a}, X_{3a} \}$.
For any pair of atoms $(a,a')$, we can compute the overlap element
\begin{equation}
  \braket{ \chi_{a n_x n_y n_z} }{ \chi_{a' n'_x n'_y n'_z} } = \prod_{i=1}^D
  \int\mathrm d x_i \  \psi^{[1D]}_{n_{x_i}}((x_i - X_{ia})/\sigma_a)
                    \  \psi^{[1D]}_{n'_{x_i}}((x_i - X_{ia'})/\sigma_{a'})
  \label{eqn:overlap-factorized}
\end{equation}
In each of the integrals we can exploit that the product 
of two Gaussians with spread $\sigma_a$ and $\sigma_{a'}$ 
centered at $x_a$ and $x_{a'}$, respectively, 
is again a Gaussian $\exp(-\vec r^2 \sigma_p^{-2})$ with spread $\sigma_p = \left(\sigma_a^{-2} + \sigma_{a'}^{-2}\right)^{-\frac12}$
centered at $\sigma_p^2 \left( \sigma_a^{-2} \vec R_a + \sigma_{a'}^{-2} \vec R_{a'} \right)$.
The polynomial expressions can be shifted to the new center and multiplied there.
See fig.~\ref{fig:overlap_1D} for an impression of the 1D overlap values 
as a function of distance the centers.
Finally, the integration reduces the the evaluation of the kernel
\begin{equation}
  I_k = \int\limits_{-\infty}^{\infty} \mathrm d x \  \exp(-x^2) \  x^{2k}
  \label{eqn:gauss-integral-kernel}
\end{equation}
which can be evaluated recursively by $I_{k+1} = (k + \frac12)\,I_k$ starting at $I_0 = \sqrt{\pi}$.
Mind that no approximations are required here.
%
\begin{figure}
	%%% how to generate this plot:
	%%% make -j && ./aa3 -t sho_overlap. +verbosity=9 | grep 'test_Hermite_Gauss_overlap' | sed -e 's/# test_Hermite_Gauss_overlap  distance=//g'
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/overlap_1D} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:overlap_1D}
  \caption{
	The overlap integral values of two 1D \ac{ho} eigenfunctions (both with spread $\sigma$)
	as a function of distance between their centers.
	Only an upper triangle of combinations $(n,n')$ up to $n\um{max} = 3$ is shown.
  }
\end{figure}
%
%


\subsubsection{Hamiltonian matrix elements}
The \ac{dft} Hamiltonian consists of a kinetic energy operator,
a local effective potential 
and, if the basis is incapable of
capturing the rapid oscillations close to the nuclei,
a non-local contribution according to the \ac{paw} method.
A similar \ac{paw} contribution would then also appear in the overlap operator.
The kinetic energy consists of a Laplacian so we can boil it down to the evaluation
of $\braketop{ \psi^{[1D]}_{an} }{ \partial^2_x }{ \psi^{[1D]}_{a'n'} }$.
This works just as outlined for the overlap elements
except for the derivative operator modifying the polynomials.
Mind that in order to produce symmetric matrix elements,
a first derivative should be applied to the left and a first derivative to the right.
It is easy to show that applying the second derivative to the left in general differs from
the matrix element that we obtain if we apply the second derivative to the right.

The non-linearity of the exchange-correlation potential in \ac{dft} usually
leads to a representation of the local potential $V(x,y,z)$ on a real-space grid.
We will assume a Cartesian uniform grid here.
Then, viable options would be
\begin{itemize}
%
\item to evaluate $\braketop{ \chi }{ \hat V }{ \chi' }$ numerically. 
This may lead to a large cost prefactor but scales linearly due to the localization of $\chi$s.
%
\item for each pair $(a,a')$ which is not too distant
compute an expansion of $V(\vec r)$ into a \ac{sho} basis with spread $\sigma_p$
at the common center and do the product and integral there. Still costly.
%
\item for each atom $a$ expand $V(\vec r)$ into a suitable \ac{sho} basis. 
Then, we can insert a completeness relation: %%  (truncation of unity?)
\begin{equation}
 \braketop{ \chi_{a\vec n} }{ \hat V }{ \chi_{a'\vec n'} } = \sum_{\vec n''}
 \braketop{ \chi_{a\vec n} }{ \hat V }{ \chi_{a\vec n''} } \braket{ \chi_{a\vec n''} }{ \chi_{a'\vec n'} }
\end{equation}
such that all Gaussian are centered at the position of atom $a$ for the expectation value
and the second integral is the same as for the overlap operator.
Mind that we inserted a complete basis $\chi_{a\vec n''}$. 
This means that the convergence w.r.t.~the cut-off for $\vec n''$ needs to be checked carefully.
Due to different convergence rates, the potential matrix $\hat V$ might not be symmetric
requiring symmetrization according to $\hat V\um{sym} = \frac 12 \left( \hat V + \hat V^\dagger \right)$.
%
\end{itemize}
In the following, we will pursue the latter approach.

Finally, non-local potentials are usually expressed as dyadic operators
$\ket{\tilde p^a_i} D^a_{ij} \bra{\tilde p_j}$ with localized projector functions $\tilde p_i(\vec r)$
centered at the atomic positions.
% We can expand the projectors in a suitable \ac{sho} basis and use the same method
% as for overlap elements~\cite{BaumeisterTsukamotoPASC19}.
We can expand the projectors in a suitable \ac{sho} basis and use the same method
as for matrix elements of the local potential.~\cite{BaumeisterTsukamotoPASC19}.

%
\begin{figure}
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/GaussianProductRule} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:GaussianProductRule}
  \caption{
Schematic picture to illuminate the Gaussian product rule. Blue is the product of red and green.
Due to the larger spread of the red Gaussian, the origin of the product (center of mass) is much closer to
the origin of the green Gaussian.
  }
\end{figure}
%
%


\subsubsection{Expansion of the Density}
If the local \ac{sho} basis with $\sigma$ and $\nu\um{max}$
is suitable to describe wave functions, 
a suitable \ac{sho} basis for the expansion of the density $\varrho(\vec r)$ has
spread $\sigma_a/\sqrt{2}$ and $2\nu\um{max}$.
This is due to the representation of densities
arising from basis functions local to an atom, c.f.~fig.~\ref{fig:plot_parabolas}.
%
\begin{figure}
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/plot_parabolas} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:plot_parabolas}
  \caption{
Schematic picture to illuminate the relation between the SHO basis configuration 
used to describe densities (and maybe potentials)
compared to the SHO basis for wave functions:
If wave functions are expanded into a Hermite-Gauss basis with spread $\sigma$
up to $n\um{max}$ (here, the $n\um{max} = 5$ function is shown in blue)
the square of such a wave function leads to the function shown in purple:
A Gaussian with spread $\sigma^{[\varrho]}$ times a polynomial with max.~degree $n\um{max}^{[\varrho]}$.
This function can be exactly expanded by a Hermite-Gauss basis if
$\sqrt{2}\,\sigma^{[\varrho]} = \sigma$
and
$n\um{max}^{[\varrho]} = 2n\um{max}$.
The highest Hermite-Gauss function for $n\um{max}^{[\varrho]} = 10$ is shown in red.
The associated parabolas are shown in bold black and bold green.
In the limit of large $n\um{max}$, the classical return radius $R\um{ret}$
of both SHO bases coincides (grey dashed vertical lines).
The associated cut-off energy is $4$ times higher for the density basis.
  }
\end{figure}
%
%

So for the evaluation of the density,
we have to prepare this tensor of coefficients:
\begin{equation}
	P_{nn'n''} = \int \mathrm d x \ H_{n}(x) \exp(-x^2/2) \cdot H_{n''}(x\sqrt{2}) \exp(-x^2) \cdot H_{n'}(x) \exp(-x^2/2)
\end{equation}
where the indices $n$ and $n'$ are associated with the SHO basis for wavefunctions
and $n''$ runs up to $n\um{max}^{[\varrho]}$. 
Obviously, all $P_{nn'n''}$ are zero if $n + n' + n''$ is odd.

\subsubsection{Expansion of the Local Potential}
As described above, there are several ways to evaluate the matrix elements of the local effective potential $V(\vec r)$.
For this, we have to perform the integral
\begin{equation}
	\int \mathrm d^3 \vec r  \  \psi_{n_x}(x_a)\psi_{n_y}(y_a)\psi_{n_z}(z_a)  \  V(x,y,z) \ 
	                            \psi_{n'_x}(x_{a'})\psi_{n'_y}(y_{a'})\psi_{n'_z}(z_{a'})
	                            \label{eq:local_potential_matrix_element}
\end{equation}
where $x_{ia} = x_{i} - X_{ia}$, i.e.~atom centered coordinates.
Similar to the case of the density, the product of the two Gaussian envelop functions of the 
two \ac{sho} basis functions produces a Gaussian centered at the \emph{center of mass}, here labelled $c$, where
$2\sigma^2$ is defining the inverse of the \emph{mass}.
In order to evaluate eq.~(\ref{eq:local_potential_matrix_element}) we
expand $V(x,y,z)$ in 3D factorizable polynomials, i.e.
\begin{equation}
	V(x,y,z) = \sum_{p_x p_y p_z} V_{p_x p_y p_z} (x - X_c)^{p_x} (y - Y_c)^{p_y} (z - Z_c)^{p_z}
	                            \label{eq:local_potential_polynomial_expansion}
\end{equation}
The necessary expansion coefficients $V_{p_x p_y p_z}$ can be found by SHO-transform around the common center $c$.
Then the evaluation of potential matrix elements requires only the tensors
\begin{equation}
	M_{pnn'}^{aa'[x]} = \int \mathrm d x  \  \psi_{n}(x - X_{a}) \  (x - X_{c})^{p} \  \psi_{n'}(x - X_{a'})
	\label{eq:local_moment_matrix_elements}
\end{equation}
which only need to be re-computed when atoms update their positions.
The final expression for potential matrix elements between SHO basis function $(\vec n_a,\sigma_a)$ and $(\vec n_{a'},\sigma_{a'})$ reads
\begin{equation}
	\sum_{p_x p_y p_z} V_{p_x p_y p_z} \  M_{p_x n_x n'_x}^{aa'[x]} \  M_{p_y n_y n'_y}^{aa'[y]} \  M_{p_z n_z n'_z}^{aa'[z]}
	\label{eq:local_moment_matrix_elements_from_tensors}
\end{equation}
During the SHO tranform onto the local potential we need to take care of the normalizing prefactors:
Typically, L2-normalizations are multiplied to the SHO projection coefficients 
after the projection with unnormalized Hermite-Gauss functions.
However, here, proper L1-normalization requires the matrix inverse of 
$$ f_{nm\sigma} = \int\limits_{-\infty}^{\infty} \mathrm dx \  H_{n}\left( \frac{x}{\sigma} \right) \  \exp\left( -\frac{x^2}{2\sigma^2} \right) \  x^m $$
%%% sho_overlap::moment_normalization
for $m \leq n$ which results in a triangular matrix that, in addition, features an even-odd parity, 
i.e.~matrix entries are only non-zero if both $m$ and $n$ are even or both are odd.

\section{Benchmark: Free Electron Gas}
The dispersion relation of the free electron gas is know to be
\begin{equation}
	E(\vec k)= \frac {\vec k^2} 2
\end{equation}
a simple parabola with its curvature related to the mass of the electron.
In a perodic setup, we have to consider also the periodic image parabolas
\begin{equation}
	E_n(\vec k) = \frac {(\vec k - \vec G_n)^2} 2
\end{equation}
As a test of the quality of \ac{sho} functions as a basis
we diagonalize the Laplacian operator that represents the
Hamiltonian.
We analyzed the three highly symmetric, cubic lattice structures with a single basis atom,
SC, BCC and FCC, finding that the overlap matrix can become singular at certain points of
the reciprocal space, see fig.~\ref{fig:overlap_lowest_eig}.
%
\begin{figure}
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/20190529_fcc_overlap_lowest_eig} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:overlap_lowest_eig}
  \caption{
	Lowest eigenvalue of the overlap operator as a function of a given path in the Brioullin zone for FCC.
  }
\end{figure}
%
%
In order to stabilize the method, the used spread $\sigma$ depends on the nearest neighbor distance $d\um{NN}$
and the basis size.
\begin{equation}
	\sigma\um{stable} = \frac34 \frac{ d\um{NN} }{ \sqrt{2 \nu\um{max} + 3} }
\end{equation}
Remember that $\sigma \sqrt{2 \nu\um{max} + 3}$ is the classical return radius.
The factor $0.75$ is chosen manually and seems to produce stable results.
%
\begin{figure}
  %% how to generate this plot:
  %%  set DoS = false in overlap.cxx test_fcc
  %% 	run -t overlap. and set Ref = true   and nmax high for the analytical reference
  %% 	run -t overlap. and set Ref = false  and nmax = 8
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/20190710_overlap_fcc8} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:overlap_fcc8}
  \caption{
	Bandstructure of the free electron gas. The analytical solution is shown in red
	whereas the black lines show the \ac{sho} basis result for $\nu\um{max} = 8$ and $\sigma = 1.2$ Bohr 
	while the FCC lattice constant is $8$ Bohr.
  }
\end{figure}
%
%
Since we know that eigenstates of the free electron Hamiltonian are plane waves,
this gives an estimate of how good a \ac{sho} basis is capable of describing
smooth quantities in full space. 
In fig.~\ref{fig:overlap_fcc8} we can see that the black lines are on top of the 
analytical solutions for lower energies and above that in the upper half.
In order to study the deviations better,
we have a look at the integrated \ac{dos}.
For this we diagonalize the free electron Hamiltonian for each $\vec k$-point
in the irriducible wedge of the Brillouin zone
and compare again with the integrated \ac{dos} derived from the analytical solution $E_n(\vec k)$
with the same sampling.
Fig.~\ref{fig:overlap_DoS_free_electron_fcc} shows the result for $\nu\um{max} \in [0, 9]$,
each using its distinct $\sigma\um{stable}$.
The plot helps to quantify the deviations. For example with $\nu\um{max} = 9$, the \ac{sho}
basis describes the free electron gas well up to about $5$ Rydberg, 
but features solutions up to $20.8$ Rydberg where the highest analytical solution
within $220$ states is only $13.7$ Rydberg,
c.f.~the red and black dot in fig.~\ref{fig:overlap_DoS_free_electron_fcc}.
%
\begin{figure}
  %% how to generate this plot:
  %%  set DoS = true in overlap.cxx test_fcc
  %% 	run -t overlap. and set Ref = true   and nmax high for the analytical reference
  %% 	run -t overlap. and set Ref = false  and scan through nmax from 0..9
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/overlap_DoS_free_electron_fcc} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:overlap_DoS_free_electron_fcc}
  \caption{
	Integrated density of states of the free electron gas. The analytical solution is shown in red
	whereas the black lines show the \ac{sho} basis result up to $\nu\um{max} = 9$.
% 	and $\sigma = 1.2$ Bohr while the FCC lattice constant is $8$ Bohr. // ToDo: check sigma and alat
  }
\end{figure}
%
%
\begin{figure}
  %% how to generate these plots: tests/free_electron.sh
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=.7\textwidth]{fig/free_electron_sc} %%
	\includegraphics[width=.7\textwidth]{fig/free_electron_bcc} %%
	\includegraphics[width=.7\textwidth]{fig/free_electron_fcc} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:overlap_DoS_free_electron_cubic_lattices}
  \caption{
	Integrated density of states of the free electron gas. The analytical solution is shown in red
	whereas the black lines show the \ac{sho} basis result up to $\nu\um{max} = 9$ 
	for cubic lattice structures SC, BCC, FCC (top to bottom).
  }
\end{figure}
%
%
\section{All electron calculations}\label{sec:all-electron}
%
\begin{figure}
  %% how to generate this plot:
  %% 	run -t atom_core.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/atom_core_LDA_dots} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:atom_core_levels}
  \caption{
	Eigenenergies of self-consistent neutral isolated spherical spin-paired atom calculations with LDA.
  }
\end{figure}
%
%

\section{Exact Poisson solver}
%
% \begin{figure}
%   %% how to generate this plot:
%   %% 	run -t atom_core.
%   \begin{minipage}[c]{.990\textwidth}
% 	\includegraphics[width=\textwidth]{fig/fourier_poisson} %%
%   \end{minipage}\hfill
%   \begin{minipage}[c]{.009\textwidth}
%   \end{minipage}
%   \label{fig:fourier_poisson_solver}
%   \caption{
% 	Comparison of input and output of the (3D periodic) \ttt{fourier\_poisson.}-solver with (isolated 1D) radial solutions.
% 	Differences might stem from the different boundary conditions.
%   }
% \end{figure}
%
%
A Poisson solver based on Fourier-transforms (FFT by Intel Math Kernel Library)
is implemented to be able to exclude artifacts from e.g.~iterative Poisson solvers
when developing other modules of the code. 
It serves also as a reference so estimate the precision of other Poisson solvers
as the treatment in reciprocal space is analytically exact.


\section{Live Atoms}\label{sec:live_atoms}
%
\begin{figure}
  %% how to generate this plot:
  %% 	run -t single_atom.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/single_atom_Cu_smooth_partial_waves_order3} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:single_atom_Cu}
  \caption{
	True wave functions for core states and valence states, 
	smooth pseudized wave functions for valence states of copper.
  }
\end{figure}
%
%
The module \ttt{single\_atom.} starts from a self-consistent calculation by loading 
\ttt{pot/Zeff.00}$Z$ where $Z$ is the atomic number.
The files store $Z\um{eff}(r)$ i.e.~the screening of the nuclear charge.
It can be converted to the self-consistent spherical true potential
\begin{equation}
	V\um{tru}(r) = -\frac{Z\um{eff}(r)}{r}
\end{equation}
however, the core solver used \ttt{atom\_core.} takes $rV(r)$ as input so
we only need to modify the sign.
The advantage of storing $Z\um{eff}$ is that the numbers stay in a regular range
and users can distinguish files simply by looking at the \ttt{head} of the file.
%
\begin{figure}
  %% how to generate this plot:
  %% 	run -t single_atom.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/RamerDouglasPeucker_reduction} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:RamerDouglasPeucker_reduction}
  \caption{
	Applying algorithms from vector graphics allows to sparsify and reduce 
	the file sizes for input data.
  }
\end{figure}
%
When storing $Z(r)$ instead of $rV(r)$ typically all numbers are positive 
which facilitates plotting on a log scale.
This way of representation also allows for data compression of the files:
$Z\um{eff}(r)$ is a monotonously falling function from $Z$ at the origin to $q$ at the
end of the radial grid (assume that atom has total charge $q$).
It is sampled on the same grid that is used to solve for core and valence states,
i.e.~it often features more than 2000 radial grid points.
Using the sparsification method for path data by Ramer/Douglas and Peucker,
we can reduce the number of radial support points below 500 (1000) points while
the deviations are not larger than $10^{-6}$ ($10^{-11}$), 
c.f.~fig.~\ref{fig:RamerDouglasPeucker_reduction}.


From the self-consistent spherical potential, we compute the eigenenergies
of all occupied atomic eigenstates.
Then, we distinguish which of those are to be considered as valence states, 
typically by an energy criterion, e.g.~\unit[1]{Ha} below zero.

The module has an update function which then envokes updates on the following parts
\begin{itemize}
 \item true core states from true spherical potential
 \item true core density from core occupations, mix with previous
 \item smooth core density
 \item energy parameters and true partial waves
 \item smooth partial waves
 \item charge deficit tensor
 \item density matrix from valence occupations (isolated mode only)
 \item density tensor from density matrix
 \item true and smooth density from density tensor
 \item compensation charges from density tensor
 \item smooth augmented density from smooth density and compensators
 \item true and smooth potential from corresponding densities
 \item zero potential $\bar V$ by parabola matching
 \item extract spherical potentials, mix with previous
 \item matrix elements for atomic Hamiltonian and overlap operator 
		from potentials and corresponding partial waves
\end{itemize}

This workflow can be iterated to let the atomic data relax.
In the isolated mode, the energy parameters for the true partial waves are chosen as valence eigenenergies
and the density matrix is prepared to represent spherically symmetrized valence occupations.
Then, it can be verified that the self-consistent potential that was input is
not changing any more when iterated in the \ttt{single\_atom.} update cycle.

In full operation, density matrix, energy parameters and electrostatic multipoles
are input from outside and only atomic Hamiltonian correction, projector functions
and charge deficit matrix for the atomic overlap operator are output. 




\section{Spherical Atoms}\label{sec:spherial-atoms}
%
The \ttt{spherical\_atoms.} mode aims to
make a cheap module to find the initial
charge density of very large calculations.
It is based on LiveAtoms (see sec.~\ref{sec:live_atoms})
and their isolated mode, i.e.~the density matrix is generated from valence occupation numbers.
Currently, the atomic densities and potentials are restricted to
stay spherical (only $\ell = 0$ terms) so
also the valence occupation numbers are averaged whithin the shells.
This constraint could be relased in the future.

The atoms export a smooth density (currently only a spherical core density, 
therefore also valence states need to be treated as core states)
which is brought to a 3D grid.
There, we evaluate the exchange-correlation potential and, after adding 
appropriate charge compensators, also the electrostatic potential.
The Poisson equation is so far solved using FFTs but this will be
replaced by a multi-grid accelerated iterative Poisson solver based on a
high-order finite-difference Laplacian since this is more flexible
in terms of boundary conditions and scalability.
Then, the 3D smooth effective potential is projected to a radial basis
for each atom center and these potentials are fed back into the LiveAtom module.

Probably, we should make an intermediate module that takes care of
valence treatment of single atoms on coarse radial grids with an artificial confinement potential.
This would then be able to capture $m$-resolution.

With the spherical constraint as-is,
we could let the valence occupation numbers relax 
in order to get the initial charge transfer right.
For this, only the height of the smooth effective potential at
the position of each atom needs to be communicated to the LiveAtom objects.
It can be done by the $v^a_{00}$ term which is found by projection 
$\braket{\hat n^a_{00}}{V\um{es}(\vec r)}$.



\subsection{On the shape of compensators}\label{sec:compensator-radii}
In order to get $v^a_{00}$ correct, we have to assume that there is no overlap
between charge compensation densities of two different atoms
which leads to very localized compensators.
The GPAW choice $r\um{aug}/\sqrt{10}$ leads to only a fraction of $1.7\cdot 10^{-4}$ of the total charge of the compensator
outside of $r\um{aug}$ which is probably a good compromise in terms of accuracy and cost.
With a typical $r\um{aug} =$\unit[2]{Bohr}, the compensation charge shapes
$\exp(-10\frac{r^2}{r\um{aug}^2}) = \exp(-\frac{r^2}{2 \sigma^2})$
has $\sigma = r\um{aug}/\sqrt{20} = $\unit[0.447]{Bohr}.
The corresponding grid cutoffs are $3\sigma^{-2} = $\unit[15]{Rydberg}
which requires a grid spacing of at most \unit[0.811]{Bohr}.
For first row elements, the augmentation radii can be 
of the order of 1.0 and even \unit[0.9]{Bohr} for hydrogen.
So the max.~grid spacing would be \unit[.365]{Bohr}.
In order to be accurate enough, we would like to
keep the density grids at a grid spacing of \unit[.236]{Bohr}
so that there are $8^3$ grid points in one \AA$^3$.


%
\begin{figure}
  %% how to generate this plot:
  %% 	run -t single_atom.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/larger_compensation_radii} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:larger_compensation_radii}
  \caption{
	Increasing the $r\um{cut}$ of the compensation charge densities
	to $2\times$, $3\times$ and $4\times$ the typical $r\um{aug}/\sqrt{10}$
	used by GPAW shows that the zero potential $\bar V$ becomes much smoother
	and even attractive (here shown for aluminum, $r\um{aug} =$ \unit[2]{Bohr}).
  }
\end{figure}
%
%
In the spirit of Ewald's method we could make the compensation charges
softer, i.e.~allow a larger radius. However, then we need correction
potentials.
In PAW, the potential contribution $\bar V$ is added only inside the sphere.
Figure \ref{fig:larger_compensation_radii} shows that $\bar V$ extends beyond
$r\um{aug}$ if we increase $r\um{cut}$.
We probably have to consider to have two different corrections:
The traditional localized $\bar V$ which fills the potential well inside the sphere
and a new correction for extended very smooth compensators.
The, the latter is added after solving the Poisson equation.
After adding, we can make the projection with the more localized compensation charges.
And then add the traditional $\bar V$ to get to the effective potential.

\subsection{The zero potential}

In order to reproduce the exact total effective potential outside 
%
\begin{figure}
   %%% how to reproduce this:
   %%% git key 9f115f160f63d6cf7df64cf60de547293d8d5ca6 
   %%% make -j && ./aa3 -t spherical_atoms. +verbosity=11  +single_atom.echo=6 > out
   %%% and rune once again with
   %%% manipulated prefactor (e.g. insert 0 instead of Y00 in spherical_atoms.cxx:343)
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/20200131_zero_potential_inset_times_r} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:zero_potential}
  \caption{
	Radial projection of the effective potential $V\um{tot} = V\um{xc} + V\um{es}$
	Before adding the localized spherical atom contributions $\bar V^{a}$,
	a strong potential dip can be seen at the positions of the two atoms Al and P in a dimer.
	Furthermore, there is a faint dip around \unit[4]{Bohr} which indicates the position of the other atom, 
	see inset. For better visibility, the inset shows $r\,V(r)$.
  }
\end{figure}
%
%


\subsection{Communicating the potential shifts}\label{sec:multipole-shifts}
Different spheres in the PAW framework communicate via the electrostatic
potential which is to be evaluated in 3D for the smooth quantities
and inside the spheres for both, smooth and true quantities on radial grids.
The charge deficits $q^a_{\ell m}$ inside each sphere are
brought to the 3D grid with the help of localized smooth compensator charge densities 
(see sec.~\ref{sec:compensator-radii}).
%
\begin{figure}
  %% how to generate this plot:
  %% 	run -t spherical_atoms.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/finding_electrostatic_multipole_shifts} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:multipole-shifts}
  \caption{Smooth electrostatic potentials of an A$-$B dimer with ionization, here Al$^+ -$P$^-$.
  In the radial representation, the electrostatic problem is first solved disregarding boundary conditions (dotted lines).
  Then, the radial solutions are shifted to match $v_{\ell m}$ as found by projection with the compensator shapes.
  The shifted radial solutions (solid lines) and a Bessel projection of the 3D solution match inside the spheres (radii 2 Bohr).}
\end{figure}
%
%
After solving for the 3D electrostatic potential $\tilde V\um{es}(\vec r)$,
we can probe the value and derivatives of the potential at the nuclear site, $V\um{es}(\vec R^a)$,
however, in order to avoid egg-box effects we
probe by a projection to the charge compensator shape:
$$ v^a_{\ell m} = \int d^3 \vec r \  \hat g_{\ell m}(\vec r) \tilde V\um{es}(\vec r) $$
See fig.~\ref{fig:multipole-shifts} for an example.

\begin{figure}
  %% how to generate this plot:
  %% 	run -t spherical_atoms. +spherical_atoms.test.ion=.0 +spherical_atoms.max.scf=19 +single_atom.echo=9
  %% 	run -t spherical_atoms. +spherical_atoms.test.ion=.9 +spherical_atoms.max.scf=19 +single_atom.echo=9
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/20200127_spherical_atoms_ionized0} %%
	\includegraphics[width=\textwidth]{fig/20200127_spherical_atoms_ionized9} %%
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:ionized-spherical-atoms-AlP-dimer}
  \caption{
   Smooth electrostatic potentials of an Al$-$P dimer 
   without ionization (upper panel) and ionized Al$^{+.9}$P$^{-.9}$ (lower panel).
   Ionization shifts the potential value at the origin down for Al (by \unit[-67.9]{mHa} or \unit[-1.85]{eV})
   and up for P (by \unit[54.3]{mHa} or \unit[1.47]{eV}).
   %%% how to find this value?
   %%% for Al grep '0.000100923'  20200127_spherical_atoms_ionized*.agr
   %%% for P  grep '0.000101042'  20200127_spherical_atoms_ionized*.agr
    %%% the first column here is V(r) and the seconds is the projected V(xyz)
	% # for Al
	% 20200127_spherical_atoms_ionized0.agr:0.000100923 -2.34213 -2.33898
	% 20200127_spherical_atoms_ionized9.agr:0.000100923 -2.41004 -2.40433
	% # for P
	% 20200127_spherical_atoms_ionized0.agr:0.000101042 -3.07102 -3.0669
	% 20200127_spherical_atoms_ionized9.agr:0.000101042 -3.01669 -3.01555
   }
\end{figure}



\section{Linear Scaling}\label{sec:linear-scaling}
%
A first glimpse of linear scaling algorithms can be found in the
\ttt{geometry\_analysis.} module.
Here, all target atoms in the vicinity of $r\um{vic} = \unit[6.144]{\AA}$ around each source atoms
have to be found in order to analyse its local bond structure
and coordination number.
A naive implementation leads to an $N\um{atoms}^2$-scaling algorithm,
in fact, the distance of $n\um{images} \cdot N\um{atoms}^2$ atom-atom pairs
needs to be visited.
Although we can compare the squared distance to the squared radius of the vicinity,
hence omitting the computation of the sqaure root, the cost prefactor
is in the range of one nanosecond on a single core CPU.
For example the CPU runtimes shown in fig.~\ref{fig:geometry-analysis-scaling}
are $t \approx n\um{images} \cdot N\um{atoms}^2 \cdot \unit[1.78]{ns}$, c.f.~red data points.
%%%% 27*1e6^2 atom-atom pairs in 48116.43 sec
\\
A linear scaling algorithm that produces the same output comes at the additional
cost of an initial grouping operation of the atomic positions into clusters.
However, as we know the spatial position and max.~extend of the clusters,
it is simple to analyze only atom pairs where the clusters of both partners
are not too remote.
A simple treatment in 3D is to generate uniform rectangular boxes. 
The min.~box extend is $r\um{vic}$.
Periodic images of boxes need to be taken into account.
If the simulation cell is large, a halo thickness of 1 needs is sufficient.
The initial (linear scaling) operation is to generate lists of those atoms
that are located inside each box.
%
\begin{figure}
  %% how to generate this plot:
  %%    rm -f atoms.xyz && ln -s gst_set128.xyz ./atoms.xyz
  %% 	time run -t geometry_analysis.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/geometry_analysis-scaling} %% .agr .pdf
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:geometry-analysis-scaling}
  \caption{
  Linear scaling vs.~quadratic scaling can be observed when computing atom-atom distances.
  The dashed lines have slope 1 and 2, respectively, fitted through a single data point.
  The crossover of the dashed lines happens around $13$ atoms 
  whereas the measured data (circles) cross around $32$ atoms.
  }
\end{figure}
%
%
This solution leads to a time requirement $t \approx N\um{atoms} \cdot \unit[633]{ns}$.
% Comparing these prefactors
% we can extrapolate a theoretical crossover for this particular case (bulk, cubic cell) around $13$ atoms.
% For any larger number of atoms, the linear scaling solution is faster.

\section{SHO Projectors}

%
\begin{figure}
  %% how to generate this plot:
  %%    assert(echo_prj);
  %% 	time run -t single_atom.
  \begin{minipage}[c]{.990\textwidth}
	\includegraphics[width=\textwidth]{fig/sho_radial} %% .agr .pdf
  \end{minipage}\hfill
  \begin{minipage}[c]{.009\textwidth}
  \end{minipage}
  \label{fig:sho-radial-projectors}
  \caption{
  Radial projectors for $\sigma = \unit[0.5]{Bohr}$ and $\nu\um{max} = 3$.
  }
\end{figure}
%
%
A set of $6$ radial \ac{sho}-projectors is shown in fig.~\ref{fig:sho-radial-projectors}.
With the multiplicity of the spherical harmonics ($2\ell$+$1$) this leads to 
$$2 \times 1 + 2 \times 3 + 1 \times 5 + 1 \times 7 = 20$$
projectors when exanded on the 3D grid.
However, the expansion happens in the factorizable representation of the
\ac{sho}-eigenstates: all products of the Hermite polynomials 
$H_{n_x}(x) \cdot H_{n_y}(y) \cdot H_{n_z}(z)$ 
times a Gaussian envelope function $\exp(-\frac12 r^2)$
for which $n_x + n_y + n_z \leq \nu\um{max}$ span the same function space
as radial \ac{sho}-eigenfunctions functions times spherical harmonics.
The factorizable representation comes with the advantage that the 1D functions,
e.g.~$H_{n_x}(x) \cdot \exp(-\frac 12 x^2)$ can be evaluated on-the-fly 
at affordable costs~\cite{BaumeisterTsukamotoPASC19}.

\subsection{Normalization}
In the factorizable representation, one could infer L2-normalization of each 1D projector. 
However, this involves serveral \ttt{sqrt}-operations and divisions which can be avoided
by applying scaling factors such as normalizations in
after the projection or in advance of the addition operation.
The recursive definition of the Hermite polyomials is
\begin{equation}
	H_{\nu + 1}(x) = x H_{\nu} - \frac{\nu}{2} H_{\nu - 1}
\end{equation}
where $\nu$ is $n_x$, $n_y$ or $n_z$, respectively.
(compare \ttt{hermite\_polynomial.hxx}) 
With that and the decay factor $\exp\left({-\frac{x^2}{2\sigma^2}}\right)$
for each vector component $x$, $y$ and $z$
we find that 1D Hermite-Gauss projectors are L2-normalized by a prefactor
\begin{equation}
	f_{\nu} = \sqrt{ \frac{2^{\nu}} {\sqrt{\pi} \sigma \nu!} }
\end{equation}
And, hence, the 3D Cartesian factorizable projectors are L2-normalized by the prefactor
\begin{equation}
	f_{n_x n_y n_z} = \sqrt{ \frac{2^{n_x + n_y + n_z}} {\sqrt{\pi^3} \sigma^3 n_x! n_y! n_z!} }
\end{equation}


\subsection{Normalization for electrostatic}
For the preparation of neutral charge distributions despite charge deficits in the core and the partial waves
compensator charges $\hat q_{\ell m}(\vec r)$ are used.
These also follow the Gaussian shape function %% reference needed, e.g. GPAW (but GPAW usues \exp(-\frac{\vec r^2} {r_c^2})
\begin{equation}
 \hat q_{\ell m}(\vec r) = f_{\ell} \exp(-\frac{\vec r^2} {2\sigma^2}) Y_{\ell m}(\hat{\vec r}) |\vec r|^\ell
\end{equation}
which makes it suitable to use the projection and addition routines for factorizable projectors,
although we do not require any contributions with $\nrn > 0$.
Different from the L2-normalization, the L1-normalization factor $f_\ell$ for electrostatics is determined by
\begin{align}
 1 &= \int \mathrm d^3\vec r  \  \hat q_{\ell m}(\vec r) Y^*_{\ell m}(\hat{\vec r}) |\vec r|^\ell \\
 f_\ell^{-1} &= \int\limits_0^\infty \mathrm d r r^2 \exp(-\frac{r^2} {2\sigma^2}) r^{2\ell} \\
 f_\ell^{-1} &= \sigma^{2\ell + 3} \int\limits_0^\infty \mathrm d x \exp(-\frac{x^2}{2}) x^{2\ell + 2} \\
 f_\ell^{-1} &= \sigma^{2\ell + 3} (2\ell + 1)!! \sqrt{\frac{\pi}{2}} \\
 f_\ell &= \frac{\sqrt{2}}{\sqrt{\pi} \sigma^{2\ell + 3} (2\ell + 1)!!}
\end{align}
where we used that $\int\limits_0^{\infty} x^{2m} \exp(-x^2/2) \mathrm dx  = \sqrt{\pi/2} (2m-1)!!$ for $m \in \mathbb N_0$.
See \ttt{sho\_projection::radial\_L1\_prefactor} for an implementation of $f_\ell$.

Before we use the unitary SHO transform from Cartesian to radial,
Cartesian coefficients need to be normalized.
After transformation, we have to see that also the radial SHO eigenfunctions are L2-normalized.
For $\nrn = 0$ the Laguerre polynomial is a constant only, so
the radial L2-normalization is given by
\begin{align}
	f^{-2}_{L2} &= \int\limits_0^\infty \mathrm dr r^2 \left( r^\ell \exp(-\frac{r^2}{2\sigma^2}) \right)^2 \\
				&= \sigma^{2\ell + 3} \int\limits_0^\infty \mathrm dx x^{2\ell + 2} \exp(-x^2) \\
				&= \sigma^{2\ell + 3} (2\ell + 1)!! \frac{\sqrt{\pi}}{2^{2+\ell}} \\
\end{align}
See \ttt{sho\_projection::radial\_L2\_prefactor} for an implementation of $f_{L2}$ as a function of $\ell$.
However, we need the (L1-)normalization described above, so we introduce a proper re-scaling factor.




% ==============================================================================
\bibliographystyle{splncs03} \bibliography{literature}
% ==============================================================================

\end{document}
